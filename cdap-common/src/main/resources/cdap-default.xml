<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Copyright Â© 2014-2022 Cask Data, Inc.

  Licensed under the Apache License, Version 2.0 (the "License"); you may not
  use this file except in compliance with the License. You may obtain a copy of
  the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
  License for the specific language governing permissions and limitations under
  the License.
  -->
<configuration>

  <!-- General Configuration -->

  <property>
    <name>cluster.name</name>
    <value></value>
    <description>
      A cluster-based name for CDAP. It is used for scope resolution of
      preferences and runtime arguments. For example: the preference key
      "cluster.[cluster.name].my.key" would be resolved to "my.key" at
      runtime; a program can then retrieve the preference value by using
      just "my.key". The administrator can use this property to set
      different preferences for each cluster.
    </description>
  </property>

  <property>
    <name>hdfs.lib.dir</name>
    <value>${hdfs.namespace}/lib</value>
    <description>
      Common directory in HDFS for, among others, JAR files for coprocessors
    </description>
  </property>

  <property>
    <name>hdfs.namespace</name>
    <value>/${root.namespace}</value>
    <description>
      Root directory for HDFS files written by CDAP
    </description>
  </property>

  <property>
    <name>hdfs.user</name>
    <value>yarn</value>
    <description>
      User name for accessing HDFS
    </description>
  </property>

  <property>
    <name>instance.name</name>
    <value>${root.namespace}</value>
    <description>
      Determines a unique identifier for a CDAP instance. It is used for
      providing authorization to a particular CDAP instance. Must be
      alphanumeric, and should not be changed after CDAP has been started.
      If it is changed, there is a risk of losing data (for example,
      authorization policies).
    </description>
  </property>

  <property>
    <name>network.proxy.address</name>
    <value></value>
    <description>
      A SOCKS 5 proxy address for CDAP to proxy outgoing connections.
      The address must be in the format of "host:port".
    </description>
  </property>

  <property>
    <name>local.data.dir</name>
    <value>data</value>
    <description>
      Data directory for CDAP Local Sandbox and the CDAP Master process in
      Distributed CDAP
    </description>
  </property>

  <property>
    <name>mapreduce.include.custom.format.classes</name>
    <value>true</value>
    <description>
      Indicates whether to include custom input/output format classes in the
      job.jar or not; if set to true, custom format classes will be added to
      the job.jar and available as part of the MapReduce system classpath
    </description>
  </property>

  <property>
    <name>mapreduce.jobclient.connect.max.retries</name>
    <value>2</value>
    <description>
      Indicates the maximum number of retries the JobClient will make to
      establish a service connection when retrieving job status and history
    </description>
  </property>


  <property>
    <name>mapreduce.status.report.interval.seconds</name>
    <value>60</value>
    <description>
      Time in seconds between reporting the status, including retrieval of
      the job's task report, while a MapReduce program is running.
    </description>
  </property>

  <property>
    <name>master.manage.hbase.coprocessors</name>
    <value>true</value>
    <description>
      Whether CDAP Master should manage HBase coprocessors. This should only
      be set to false if you are managing coprocessors yourself in order to
      support rolling HBase upgrades.
    </description>
  </property>

  <property>
    <name>master.environment.extensions.dir</name>
    <value>/opt/cdap/master/ext/environments</value>
    <description>
      Semicolon-separated list of local directories that are scanned for
      CDAP Master environment providers.
    </description>
  </property>

  <property>
    <name>master.startup.checks.classes</name>
    <value></value>
    <description>
      Comma-separated list of classnames for checks that will be run before
      the CDAP Master starts up. If any of the checks fails, the CDAP Master
      will not start up. Checks will only be run if
      ${master.startup.checks.enabled} is set to true.
    </description>
  </property>

  <property>
    <name>master.startup.checks.enabled</name>
    <value>true</value>
    <description>
      Whether checks should be run before startup to determine if the CDAP
      Master can be run correctly. Which checks are run is determined by the
      ${master.startup.checks.packages} and ${master.startup.checks.classes}
      settings. If any checks fail, the CDAP Master will fail to start
      instead of waiting for the problem to be fixed. This setting only
      affects Distributed CDAP. It does not apply to CDAP Local Sandbox.
    </description>
  </property>

  <property>
    <name>master.startup.checks.packages</name>
    <value>io.cdap.cdap.master.startup,io.cdap.cdap.data.startup</value>
    <description>
      Comma-separated list of packages containing checks that will be run
      before the CDAP Master starts up. If any of the checks fails, the CDAP
      Master will not start up. Checks will only be run if
      ${master.startup.checks.enabled} is set to true.
    </description>
  </property>

  <property>
    <name>namespaces.dir</name>
    <value>namespaces</value>
    <description>
      The sub-directory of ${hdfs.namespace} in which namespaces are stored
    </description>
  </property>

  <property>
    <name>namespaces.creation.hook.enabled</name>
    <value>false</value>
    <description>
      Whether to invoke a master environment-specific method hook upon namespace creation.
    </description>
  </property>

  <property>
    <name>root.namespace</name>
    <value>cdap</value>
    <description>
      Root for this CDAP instance; used as the parent (or root) node for
      ZooKeeper, as the directory under which all CDAP data and metadata is
      stored in HDFS, and as the prefix for all HBase tables created by
      CDAP; must be composed of alphanumeric characters
    </description>
  </property>

  <property>
    <name>location.cache.path</name>
    <value></value>
    <description>
      Local directory for caching remote location content
    </description>
  </property>

  <property>
    <name>location.cache.expiration.ms</name>
    <value>86400000</value>
    <description>
      Location cache expiration time in milliseconds
    </description>
  </property>

  <property>
    <name>thrift.max.read.buffer</name>
    <value>16777216</value>
    <description>
      Specifies the maximum read buffer size in bytes used by the Thrift
      service; value should be set to greater than the maximum frame sent on
      the RPC channel
    </description>
  </property>

  <property>
    <name>twill.java.heap.memory.ratio</name>
    <value>0.6</value>
    <description>
      The minimum ratio of heap to non-heap memory for all launched Apache Twill
      containers. Container-specific settings also exist for CDAP system containers.
    </description>
  </property>

  <property>
    <name>twill.java.reserved.memory.mb</name>
    <value>768</value>
    <description>
      Desired reserved non-heap memory in megabytes for all launched Apache Twill containers.
      The actual value is bounded by the ${twill.java.heap.memory.ratio} setting of the container memory size.
      Container-specific settings also exist for CDAP system containers.
    </description>
  </property>

  <property>
    <name>twill.jvm.gc.opts</name>
    <value>-XX:+UseG1GC -verbose:gc -Xloggc:&lt;LOG_DIR&gt;/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M</value>
    <description>
      Java garbage collection options for all Apache Twill containers;
      "&lt;LOG_DIR&gt;" is the location of the log directory in the
      container; note that the special characters are replaced with entity
      equivalents so they can be included in the XML
    </description>
  </property>

  <property>
    <name>twill.location.cache.dir</name>
    <value>.cache</value>
    <description>
      The relative directory name on the distributed file system for Apache
      Twill to cache generated files, to speed up launching applications.
      This directory is relative to ${root.namespace}/twill on the file
      system.
    </description>
  </property>

  <property>
    <name>twill.no.container.timeout</name>
    <value>120000</value>
    <description>
      Duration in milliseconds to wait for at least one container for Apache
      Twill runnable
    </description>
  </property>

  <property>
    <name>twill.security.master.secret.disk.name</name>
    <value>cdap-security</value>
    <description>
      The name of the Twill security disk mount which contains cdap-security.xml for master services.
    </description>
  </property>

  <property>
    <name>twill.security.master.secret.disk.path</name>
    <value>/etc/cdap/security</value>
    <description>
      The absolute directory of the Twill security disk mount which contains cdap-security.xml for master services.
    </description>
  </property>

  <property>
    <name>twill.security.worker.mount.secret</name>
    <value>true</value>
    <description>
      Whether to mount a secret disk in worker runnables.
    </description>
  </property>

  <property>
    <name>twill.security.worker.secret.disk.name</name>
    <value>cdap-security</value>
    <description>
      The name of the Twill security disk mount which contains cdap-security.xml for worker runnables.
    </description>
  </property>

  <property>
    <name>twill.security.worker.secret.disk.path</name>
    <value>/etc/cdap/security</value>
    <description>
      The absolute directory of the Twill security disk mount which contains cdap-security.xml for worker runnables.
    </description>
  </property>

  <property>
    <name>twill.yarn.am.memory.mb</name>
    <value>512</value>
    <description>
      The memory size in megabytes of the Apache Twill application master container
    </description>
  </property>

  <property>
    <name>twill.yarn.am.reserved.memory.mb</name>
    <value>${twill.java.reserved.memory.mb}</value>
    <description>
      Desired reserved non-heap memory in megabytes for Apache Twill application master container.
      The actual value is bounded by the ${twill.java.heap.memory.ratio} of the ${twill.yarn.am.memory.mb} setting.
    </description>
  </property>

  <property>
    <name>twill.zookeeper.namespace</name>
    <value>/twill</value>
    <description>
      ZooKeeper namespace prefix for Apache Twill
    </description>
  </property>

  <property>
    <name>upgrade.thread.pool.size</name>
    <value>1</value>
    <description>
      Number of threads to be used running operations concurrently during a CDAP upgrade
    </description>
  </property>

  <property>
    <name>zookeeper.client.startup.timeout.millis</name>
    <value>60000</value>
    <description>
      Duration in milliseconds to wait for a successful connection to a
      server in the ZooKeeper quorum
    </description>
  </property>

  <property>
    <name>zookeeper.quorum</name>
    <value/>
    <description>
      ZooKeeper quorum string; specifies the ZooKeeper host:port; substitute
      the quorum (FQDN1:2181,FQDN2:2181,...) for the components shown here
    </description>
  </property>

  <property>
    <name>zookeeper.session.timeout.millis</name>
    <value>40000</value>
    <description>
      ZooKeeper session timeout in milliseconds
    </description>
  </property>


  <!-- Global Configuration -->

  <property>
    <name>bootstrap.file</name>
    <value>/opt/cdap/master/bootstrap/distributed.json</value>
    <description>
      File that contains bootstrap steps that should be executed on a new CDAP instance as well
      as steps that should be executed on every restart of CDAP. Bootstrap steps include operations
      like loading system artifacts, creating the native profile, and creating the data prep
      application.
    </description>
  </property>

  <property>
    <name>system.app.config.dir</name>
    <value>/opt/cdap/master/system-app-config</value>
    <description>
      Directory that contains definitions for what system apps should be running. This directory is continuously
      monitored for new/modified config files and updating application state to match what is defined in those files.
    </description>
  </property>

  <property>
    <name>dataset.unchecked.upgrade</name>
    <value>false</value>
    <description>
      If false, any changes made to existing datasets are not deployed when
      an app is redeployed; setting this value to true allows the dataset
      changes to be deployed upon app redeployment
    </description>
  </property>

  <property>
    <name>enable.unrecoverable.reset</name>
    <value>false</value>
    <description>
      Determines if resetting CDAP should be enabled. **WARNING: Enabling
      this option makes it possible to delete all applications and data; NO
      RECOVERY IS POSSIBLE!**
    </description>
  </property>


  <!-- Applications Configuration -->
  <property>
    <name>app.artifact.compute.hash.time.bucket.days</name>
    <value>15</value>
    <description>
      If greater than 0, ensures that has values are time bucketed every x days.
      Therefore, generating hash of an identical value x days apart will result in different hash values.
    </description>
  </property>

  <property>
    <name>app.artifact.compute.hash</name>
    <value>false</value>
    <description>
      If true, a hash for sharable artifacts will be computed and appended to artifact filename.
    </description>
  </property>

  <property>
    <name>app.artifact.compute.hash.snapshot</name>
    <value>false</value>
    <description>
      If true, a hash for sharable artifacts with SNAPSHOT in their versions will be computed and appended
      to artifact filename.
      Should only be enabled for testing purposes. Otherwise, should always remain false.
    </description>
  </property>

  <property>
    <name>app.artifact.dir</name>
    <value>/opt/cdap/master/artifacts</value>
    <description>
      Semicolon-separated list of local directories scanned for system
      artifacts to add to the artifact repository
    </description>
  </property>

  <property>
    <name>app.artifact.parallelism.max</name>
    <value>50</value>
    <description>
      Maximum parallelism of system artifact loading. This can be a resource-consuming process, e.g. with
      repository on GCS upload can use 64MB buffer, so we need to ensure app fabric is not overwhelmed during
      the process.
    </description>
  </property>

  <property>
    <name>app.bind.port</name>
    <value>0</value>
    <description>
      App Fabric service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>app.output.dir</name>
    <value>/programs</value>
    <description>
      Directory where all archives are stored
    </description>
  </property>

  <property>
    <name>app.program.extra.classpath</name>
    <value></value>
    <description>
      Additional Java classpath for CDAP programs. These extra classpaths
      must be present on all nodes in the cluster. Supports wildcard suffix
      "*" to include all JAR files under a directory.
    </description>
  </property>

  <property>
    <name>app.program.jvm.opts</name>
    <value>${twill.jvm.gc.opts}</value>
    <description>
      Java options for all Apache Twill containers
    </description>
  </property>

  <property>
    <name>app.max.concurrent.runs</name>
    <value>-1</value>
    <description>
      Maximum number of concurrent program runs allowed; set to -1 for unlimited.
      Program runs are those with an active run record.
    </description>
  </property>

  <property>
    <name>app.max.concurrent.launching</name>
    <value>-1</value>
    <description>
      Maximum number of concurrent launching runs allowed; set to -1 for unlimited.
      Launching runs have an active run record with PENDING or STARTING status.
    </description>
  </property>

  <property>
    <name>user.program.launch.disabled</name>
    <value>false</value>
    <description>Allows users to disable program launches on CDAP cluster.
      True means program launch on CDAP cluster is not allowed.</description>
  </property>

  <property>
    <name>run.record.monitor.record.age.threshold.seconds</name>
    <value>3600</value>
    <description>
      Maximum amount of time (in seconds) in which a run record is retained in run record monitor.
      This is to safe guard launch requests flow-control such that if a request is somehow stuck in PENDING/STARTING
      state, it will be dropped from after the threshold.
      Note that run.record.monitor.cleanup.interval.seconds might be needed to changed if this config changes.
    </description>
  </property>

  <property>
    <name>run.record.monitor.cleanup.interval.seconds</name>
    <value>300</value>
    <description>
      Cleanup interval (in seconds) in which run record monitor service cleanup logic runs to delete old entries.
      Note that run.record.monitor.record.age.threshold.seconds might be needed to changed if this config changes.
    </description>
  </property>

  <property>
    <name>app.program.launch.threads</name>
    <value>20</value>
    <description>
      Size of the thread pool for launching programs
    </description>
  </property>

  <property>
    <name>app.program.kill.threads</name>
    <value>20</value>
    <description>
      Size of the thread pool for force killing programs
    </description>
  </property>

  <property>
    <name>app.program.max.start.seconds</name>
    <value>300</value>
    <description>
      Maximum number of seconds to wait for a program to start before
      killing it
    </description>
  </property>

  <property>
    <name>program.twill.controller.start.seconds</name>
    <value>${app.program.max.start.seconds}</value>
    <description>
      Upon starting a program, the amount of time to wait for a program twill controller to either go into
      running or termination before returning.
    </description>
  </property>

  <property>
    <name>app.program.max.stop.seconds</name>
    <value>300</value>
    <description>
      Maximum number of seconds to wait for a program to stop before killing
      it
    </description>
  </property>

  <property>
    <name>app.program.runid.corrector.interval</name>
    <value>180</value>
    <description>
      Interval in seconds of how often the run id corrector thread will run;
      this value should be greater than 0
    </description>
  </property>

  <property>
    <name>app.program.runid.corrector.tx.batch.size</name>
    <value>1000</value>
    <description>
      Number of run records being fetched per transaction for checking if needed for correction.
      This value is directly proportional to the ${data.tx.timeout} setting.
    </description>
  </property>

  <property>
    <name>app.program.local.dataset.deleter.initial.delay</name>
    <value>300</value>
    <description>
      Interval in seconds for initial delay for the local dataset deletion thread;
      this value should be greater than 0
    </description>
  </property>

  <property>
    <name>app.program.local.dataset.deleter.interval</name>
    <value>3600</value>
    <description>
      Interval in seconds of how often the local dataset deletion thread will run;
      this value should be greater than 0
    </description>
  </property>

  <property>
    <name>app.program.terminator.interval.secs</name>
    <value>300</value>
    <description>
      Interval in seconds of how often the program terminator thread will run;
      this value should be greater than 0
    </description>
  </property>

  <property>
    <name>app.program.terminate.time.buffer.secs</name>
    <value>60</value>
    <description>
      Interval in seconds of how much buffer time is given to programs to allow them
      to stop on their own before issuing a hard kill
    </description>
  </property>

  <property>
    <name>app.program.terminator.tx.batch.size</name>
    <value>1000</value>
    <description>
      Number of run records being fetched per transaction for checking
      if a program in stopping state is active beyond its terminateTime.
      This value is directly proportional to the ${data.tx.timeout} setting.
    </description>
  </property>

  <property>
    <name>app.program.runtime.extensions.dir</name>
    <value>/opt/cdap/master/ext/runtimes</value>
    <description>
      Semicolon-separated list of local directories that are scanned for
      program runtime extensions
    </description>
  </property>

  <property>
    <name>app.program.spark.event.logs.enabled</name>
    <value>false</value>
    <description>
      Enables spark event logs collection
    </description>
  </property>

  <property>
    <name>app.program.spark.event.logs.dir</name>
    <value>spark-histories</value>
    <description>
      When ${app.program.spark.event.logs.enabled} is true, the directory under the ${root.namespace}
      for storing the logs.
    </description>
  </property>

  <property>
    <name>app.program.spark.yarn.client.rewrite.enabled</name>
    <value>true</value>
    <description>
      Specify whether to rewrite the YARN 'Client.scala' class in Spark to
      work around issue SPARK-13441 in CDH clusters
    </description>
  </property>

  <property>
    <name>app.program.status.event.fetch.size</name>
    <value>100</value>
    <description>
      Maximum number of events to fetch from the messaging system in each processing cycle for
      program status update events
    </description>
  </property>

  <property>
    <name>app.program.status.event.poll.delay.millis</name>
    <value>2000</value>
    <description>
      The delay in milliseconds to check again for new program status events after it detects there was no event
    </description>
  </property>

  <property>
    <name>app.program.yarn.attempt.failures.validity.interval</name>
    <value>60000</value>
    <description>
      The interval in milliseconds for the time window used by YARN Resource Manager to check for
      application max failure attempts. By default, this is only used for long running program, but
      can be override through runtime argument `system.yarn.attempt.failures.validity.interval`
    </description>
  </property>

  <property>
    <name>app.program.transaction.control</name>
    <value>implicit</value>
    <description>
      Defines how transactions are controlled for program methods invocation;
      "implicit" means that the platform encloses method execution into a transaction,
      whereas "explicit" means that the method itself is in control of executing transactions.
    </description>
  </property>

  <property>
    <name>app.temp.dir</name>
    <value>/tmp</value>
    <description>
      Temp directory
    </description>
  </property>

  <property>
    <name>apps.scheduler.queue</name>
    <value></value>
    <description>
      Scheduler queue for CDAP programs
    </description>
  </property>

  <property>
    <name>app.deploy.update.schedules</name>
    <value>true</value>
    <description>
      If true, redeploying an application will modify any schedules that currently exist
      for the application; if false, redeploying an application does not create any new
      schedules and existing schedules are neither deleted nor updated. This property only
      affects the redeployment of an application; all related actions or endpoints are
      unaffected.
    </description>
  </property>

  <property>
    <name>master.services.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Bind address for app fabric service and dataset service
    </description>
  </property>

  <property>
    <name>program.container.dist.jars</name>
    <value></value>
    <description>
      Additional jars to be localized to every program container and to be
      added to classpaths of CDAP programs. They can be local file paths on
      the CDAP Master or URIs of remote files. Multiple JAR files are comma-
      separated.
    </description>
  </property>

  <property>
    <name>scheduler.job.queue.num.partitions</name>
    <value>16</value>
    <description>
      Number of partitions in the scheduler's job queue. This is the same
      as the number of constraint checker threads started by the scheduler.
    </description>
  </property>

  <property>
    <name>scheduler.max.thread.pool.size</name>
    <value>100</value>
    <description>
      Size of the scheduler thread pool
    </description>
  </property>

  <property>
    <name>scheduler.misfire.threshold.ms</name>
    <value>60000</value>
    <description>
      The number of milliseconds by which a schedule execution can miss its
      next-fire-time and still run
    </description>
  </property>

  <property>
    <name>scheduler.event.poll.delay.millis</name>
    <value>2000</value>
    <description>
      The delay in milliseconds that the scheduler checks again for new events after it detects there was no event
    </description>
  </property>

  <property>
    <name>scheduler.time.event.fetch.size</name>
    <value>100</value>
    <description>
      Maximum number of events to fetch from the messaging system in each processing cycle for
      time schedule events
    </description>
  </property>

  <property>
    <name>scheduler.stream.size.event.fetch.size</name>
    <value>100</value>
    <description>
      Maximum number of events to fetch from the messaging system in each processing cycle for
      stream size schedule events
    </description>
  </property>

  <property>
    <name>scheduler.data.event.fetch.size</name>
    <value>100</value>
    <description>
      Maximum number of events to fetch from the messaging system in each processing cycle for
      data schedule events
    </description>
  </property>

  <property>
    <name>scheduler.program.status.event.fetch.size</name>
    <value>100</value>
    <description>
      Maximum number of events to fetch from the messaging system in each processing cycle for
      program status schedule events
    </description>
  </property>


  <property>
    <name>time.event.topic</name>
    <value>timeevent</value>
    <description>
      Topic name for publishing time events from time scheduler to the messaging system
    </description>
  </property>

  <property>
    <name>program.status.event.topic</name>
    <value>programstatusevent</value>
    <description>
      Topic name for publishing status transitioning events of program runs to the messaging system
    </description>
  </property>

  <property>
    <name>program.status.record.event.topic</name>
    <value>programstatusrecordevent</value>
    <description>
      Topic name for publishing program status recording events to the messaging system
    </description>
  </property>

  <property>
    <name>workflow.token.max.size.mb</name>
    <value>30</value>
    <description>
      Maximum allowed size in megabytes of a workflow token; if the workflow
      token exceeds this size, no further updates are allowed
    </description>
  </property>

  <property>
    <name>requirements.datasetTypes.exclude.list</name>
    <value></value>
    <description>
      Comma separated list of plugin datset type requirements that cannot be met in the instance.
      Plugins that require any of these will be treated as if they don't exist.
      For example, if 'table' is given, any plugin that requires 'table' will be treated as
      if they don't exist.
    </description>
  </property>

  <property>
    <name>ui.theme.file</name>
    <value>server/config/themes/default.json</value>
    <description>
      File containing the theme to be used in UI
    </description>
  </property>


  <!-- Audit configuration -->

  <property>
    <name>audit.enabled</name>
    <value>true</value>
    <description>
      Determines whether to publish audit messages
    </description>
  </property>

  <property>
    <name>audit.publish.timeout.ms</name>
    <value>2000</value>
    <description>
      Audit message publishing timeout in milliseconds
    </description>
  </property>

  <property>
    <name>audit.topic</name>
    <value>audit</value>
    <description>
      Topic name used to publish audit messages in the messaging system
    </description>
  </property>

  <!-- Datasets Configuration -->

  <property>
    <name>data.local.storage</name>
    <value>${local.data.dir}/ldb</value>
    <description>
      Database directory for LevelDB, used for data fabric in CDAP Local Sandbox
    </description>
  </property>

  <property>
    <name>data.local.storage.compression.enabled</name>
    <value>true</value>
    <description>
      Whether compression is enabled for data fabric when in CDAP Local Sandbox
    </description>
  </property>

  <property>
    <name>data.local.storage.blocksize</name>
    <value>1024</value>
    <description>
      Block size in bytes for data fabric when in CDAP Local Sandbox
    </description>
  </property>

  <property>
    <name>data.local.storage.cachesize</name>
    <value>104857600</value>
    <description>
      Cache size in bytes for data fabric when in CDAP Local Sandbox.
      Note that this value is only used by LevelDB in the JNI mode, in java mode please use
      data.local.storage.cachesize.files to control LevelDB cache
    </description>
  </property>

  <property>
    <name>data.local.storage.cachesize.files</name>
    <value>200</value>
    <description>
      Cache size in number of open files when in CDAP Local Sandbox.
      Note that this value is only used by LevelDB in java mode, in JNI mode please use
      data.local.storage.cachesize to control LevelDB cache
    </description>
  </property>

  <property>
    <name>data.event.topic</name>
    <value>dataevent</value>
    <description>
      Topic name for publishing data events to the messaging system
    </description>
  </property>

  <property>
    <name>data.storage.extensions.dir</name>
    <value>/opt/cdap/master/ext/storageproviders</value>
  </property>

  <property>
    <name>data.storage.implementation</name>
    <value>nosql</value>
    <description>
      The database implementation CDAP will use.
    </description>
  </property>

  <property>
    <name>data.storage.sql.jdbc.driver.external</name>
    <value>true</value>
    <description>
      Indicates whether the JDBC driver has to be loaded from an external directory.
      If true, then the JDBC driver directory has to be specified using
      "data.storage.sql.jdbc.driver.directory".
      If false, then the JDBC driver is present in the CDAP classpath.
      This config can only be used when the storage implementation is postgresql.
    </description>
  </property>

  <property>
    <name>data.storage.sql.jdbc.driver.directory</name>
    <value>/opt/cdap/master/ext/jdbc</value>
    <description>
      The base directory for storing JDBC driver jars.
      Sub-directory with the name that matches with the value of "data.storage.implementation" setting
      will be searched for the corresponding JDBC driver and
      dependencies jars to connect to the configured sql instance.
      The JDBC driver class to load has to be specified using "data.storage.sql.jdbc.driver.name".
      This config can only be used when the storage implementation is postgresql.
    </description>
  </property>

  <property>
    <name>data.storage.sql.jdbc.driver.name</name>
    <value></value>
    <description>
      The jdbc driver class name to connect to the sql instance. The jdbc url,
      username, password, connection properties can be set using
      cdap-security.xml.
    </description>
  </property>

  <property>
    <name>data.storage.sql.jdbc.connection.url</name>
    <value></value>
    <description>
      The jdbc url to connect to the sql instance. No sensitive information
      should be provided using the jdbc url. The username and password can
      be specified in cdap-security.xml. For non-sensitive properties, it can be
      specified by adding a property with name prefixed with "data.storage.sql.jdbc.property.",
      followed by the sql property name.
    </description>
  </property>

  <property>
    <name>data.storage.sql.scan.size.rows</name>
    <value>100</value>
    <description>
      The number of rows fetched for database reads from PostgreSQL.
    </description>
  </property>

  <property>
    <name>data.storage.sql.jdbc.connection.pool.size</name>
    <value>800</value>
    <description>
      The max number of connections for the sql connection pool.
    </description>
  </property>

  <property>
    <name>data.storage.sql.tx.runner.max.retries</name>
    <value>20</value>
    <description>
      The max number of retries for the sql transaction runner on retryable failures.
    </description>
  </property>

  <property>
    <name>data.storage.sql.tx.runner.tx.failure.delay.ms</name>
    <value>100</value>
    <description>
      The delay between retries due to transaction failures in milliseconds.
    </description>
  </property>

  <property>
    <name>data.storage.sql.tx.runner.conn.failure.delay.ms</name>
    <value>2000</value>
    <description>
      The delay between retries due to connection failures in milliseconds.
    </description>
  </property>

  <property>
    <name>data.tx.enabled</name>
    <value>true</value>
    <description>
      Determines if the transaction service is enabled.
    </description>
  </property>

  <property>
    <name>data.tx.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Transaction service bind address
    </description>
  </property>

  <property>
    <name>data.tx.bind.port</name>
    <value>0</value>
    <description>
      Transaction service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>data.tx.changeset.count.limit</name>
    <value>2147483647</value>
    <description>
      Hard limit for the number of entries in a transaction's change set;
      if exceeded, the transaction fails. By default, this is unlimited
      (that is, Int.MAX_VALUE).
    </description>
  </property>

  <property>
    <name>data.tx.changeset.count.warn.threshold</name>
    <value>50000</value>
    <description>
      Soft limit for the number of entries in a transaction's change set;
      if exceeded, a warning is logged.
    </description>
  </property>

  <property>
    <name>data.tx.changeset.size.limit</name>
    <value>9223372036854775807</value>
    <description>
      Hard limit for the aggregate size in bytes of a transaction's change set;
      if exceeded, the transaction fails. By default, this is unlimited
      (that is, Long.MAX_VALUE).
    </description>
  </property>

  <property>
    <name>data.tx.changeset.size.warn.threshold</name>
    <value>5000000</value>
    <description>
      Soft limit for the aggregate size in bytes of a transaction's change set;
      if exceeded, a warning is logged.
    </description>
  </property>

  <property>
    <name>data.tx.client.count</name>
    <value>50</value>
    <description>
      The number of pooled instances of the transaction client; increase
      this to increase transaction concurrency
    </description>
  </property>

  <property>
    <name>data.tx.client.provider</name>
    <value>pool</value>
    <description>
      Provider strategy for transaction clients; valid values are "pool" and
      "thread-local"
    </description>
  </property>

  <property>
    <name>data.tx.discovery.service.name</name>
    <value>transaction</value>
    <description>
      Name in discovery service for the transaction service
    </description>
  </property>

  <property>
    <name>data.tx.grace.period</name>
    <value>86400</value>
    <description>
      Time in seconds used to pad transaction maximum lifetime while pruning
    </description>
  </property>

  <property>
    <name>data.tx.hdfs.user</name>
    <value>${hdfs.user}</value>
    <description>
      User name for accessing HDFS (if not running in secure HDFS)
    </description>
  </property>

  <property>
    <name>data.tx.janitor.enable</name>
    <value>true</value>
    <description>
      Determines if the TransactionDataJanitor coprocessor is enabled on
      tables; normally should be true
    </description>
  </property>

  <property>
    <name>data.tx.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of transaction service instances.
      Increasing the number of transaction service instances only improves availability, but not scalability
    </description>
  </property>

  <property>
    <name>data.tx.max.timeout</name>
    <value>600</value>
    <description>
      The limit for the allowed transaction timeout, in seconds. Attempts to
      start a transaction with a longer timeout will fail.
    </description>
  </property>

  <property>
    <name>data.tx.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each transaction service instance
    </description>
  </property>

  <property>
    <name>data.tx.num.cores</name>
    <value>${master.service.num.cores}</value>
    <description>
      Number of virtual cores for the transaction service
    </description>
  </property>

  <property>
    <name>data.tx.num.instances</name>
    <value>1</value>
    <description>
      Requested number of transaction service instances
    </description>
  </property>

  <property>
    <name>data.tx.prune.enable</name>
    <value>false</value>
    <description>
      Enable invalid transaction list pruning
    </description>
  </property>

  <property>
    <name>data.tx.prune.plugins</name>
    <value>data.tx.pruning.plugin</value>
    <description>
      List of transaction pruning plugins; for CDAP HBase tables that use
      transaction functionality to skip or clean invalid data
    </description>
  </property>

  <property>
    <name>data.tx.prune.state.table</name>
    <value>${dataset.table.prefix}_system:tephra.state</value>
    <description>
      Table used to store intermediate state when invalid transaction list
      pruning is enabled
    </description>
  </property>

  <property>
    <name>data.tx.pruning.plugin.class</name>
    <value>io.cdap.data2.txprune.DefaultHBaseTransactionPruningPlugin</value>
    <description>
      Class name for the default transaction pruning plugin
    </description>
  </property>

  <property>
    <name>data.tx.retain.client.id</name>
    <value>committed</value>
    <description>
      Whether and how long to retain the client id of a transaction. Valid values are:
      "off" to disable retention of the client id; "active" to retain the client id until
      a transaction is committed; or "committed" to retain the client id as long as its
      change set participates in conflict detection. Retaining the client id slightly
      increases the memory footprint of the transaction service. Client ids are never
      retained past a restart or fail-over of the transaction manager.
    </description>
  </property>

  <property>
    <name>data.tx.server.io.threads</name>
    <value>2</value>
    <description>
      Number of IO threads for the transaction service
    </description>
  </property>

  <property>
    <name>data.tx.server.threads</name>
    <value>25</value>
    <description>
      Number of threads for the transaction service
    </description>
  </property>

  <property>
    <name>data.tx.snapshot.codecs</name>
    <value>
      org.apache.tephra.snapshot.SnapshotCodecV3,
      org.apache.tephra.snapshot.SnapshotCodecV4
    </value>
    <description>
      Specifies the class names of all supported transaction state codecs
    </description>
  </property>

  <property>
    <name>data.tx.snapshot.dir</name>
    <value>${hdfs.namespace}/tx.snapshot</value>
    <description>
      Directory in HDFS used to store snapshots and logs of transaction
      state
    </description>
  </property>

  <property>
    <name>data.tx.snapshot.interval</name>
    <value>60</value>
    <description>
      Frequency of transaction snapshots in seconds
    </description>
  </property>

  <property>
    <name>data.tx.snapshot.local.dir</name>
    <value>${local.data.dir}/tx.snapshot</value>
    <description>
      Storage directory on the local filesystem of snapshot and logs of
      transaction state when in CDAP Local Sandbox
    </description>
  </property>

  <property>
    <name>data.tx.snapshot.retain</name>
    <value>10</value>
    <description>
      Number of transaction snapshot files to retain as backups
    </description>
  </property>

  <property>
    <name>data.tx.thrift.max.read.buffer</name>
    <value>${thrift.max.read.buffer}</value>
    <description>
      Maximum read buffer size in bytes used by the transaction service; the
      value should be set to something greater than the maximum frame sent
      on the RPC channel
    </description>
  </property>

  <property>
    <name>data.tx.timeout</name>
    <value>30</value>
    <description>
      Timeout value in seconds for a transaction; if the transaction is not
      finished in that time, it is marked invalid
    </description>
  </property>

  <property>
    <name>dataset.custom.module.enabled</name>
    <value>true</value>
    <description>
      Enable the support of custom dataset module
    </description>
  </property>

  <property>
    <name>dataset.data.dir</name>
    <value>data</value>
    <description>
      Base directory for user data on the filesystem
    </description>
  </property>

  <property>
    <name>dataset.executor.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Dataset executor HTTP service bind address
    </description>
  </property>

  <property>
    <name>dataset.executor.bind.port</name>
    <value>0</value>
    <description>
      Dataset executor bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>dataset.executor.container.instances</name>
    <value>1</value>
    <description>
      Number of dataset executor instances
    </description>
  </property>

  <property>
    <name>dataset.executor.container.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each dataset executor instance
    </description>
  </property>

  <property>
    <name>dataset.executor.container.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for each dataset executor instance
    </description>
  </property>

  <property>
    <name>dataset.executor.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of dataset executor instances
    </description>
  </property>

  <property>
    <name>dataset.extensions.dir</name>
    <value>/opt/cdap/ext/lib</value>
    <description>
      Directory where all dataset extensions are stored
    </description>
  </property>

  <property>
    <name>dataset.service.bind.port</name>
    <value>0</value>
    <description>
      Dataset service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>dataset.service.boss.threads</name>
    <value>1</value>
    <description>
      Number of Netty service boss threads for the dataset service
    </description>
  </property>

  <property>
    <name>dataset.service.connection.backlog</name>
    <value>20000</value>
    <description>
      Maximum connection backlog of the dataset service
    </description>
  </property>

  <property>
    <name>dataset.service.exec.threads</name>
    <value>30</value>
    <description>
      Number of Netty service executor threads for the dataset service
    </description>
  </property>

  <property>
    <name>dataset.service.output.dir</name>
    <value>/datasets</value>
    <description>
      Directory where all dataset modules archives are stored
    </description>
  </property>

  <property>
    <name>dataset.service.worker.threads</name>
    <value>10</value>
    <description>
      Number of Netty service worker threads for the dataset service
    </description>
  </property>

  <property>
    <name>dataset.table.prefix</name>
    <value>${root.namespace}</value>
    <description>
      Prefix for dataset table name
    </description>
  </property>

  <property>
    <name>system.dataset.remote.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.dataset.remote.retry.policy.max.delay.ms</name>
    <value>5000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.dataset.remote.retry.policy.max.retries</name>
    <value>5000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.dataset.remote.retry.policy.max.time.secs</name>
    <value>7200</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.dataset.remote.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for notification publish or subscription. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>hive.version.resolution.strategy</name>
    <value>auto.strict</value>
    <description>
      Determines how to behave when the Hive version on a cluster is an unsupported value.
      The default value of "auto.strict" will require that the Hive version matches a
      supported value. Set to "auto.latest" to use the latest Hive version of CDAP
      modules available on the cluster with an unsupported Hive version.
    </description>
  </property>

  <property>
    <name>hive.server2.jdbc.url</name>
    <value></value>
    <description>
      The JDBC URL for the HiveServer2 in the cluster. This is needed if user programs
      need HiveServer2 delegation token to interact with HiveServer2. It can remain empty
      if the delegation token is not required for the user programs.
    </description>
  </property>

  <!-- Gateway Configuration -->

  <property>
    <name>app.boss.threads</name>
    <value>1</value>
    <description>
      Number of Netty service boss threads
    </description>
  </property>

  <property>
    <name>app.connection.backlog</name>
    <value>20000</value>
    <description>
      Maximum connection backlog of CDAP Master
    </description>
  </property>

  <property>
    <name>app.streaming.batch.size</name>
    <value>20</value>
    <description>
      Batch size for Batching Consumer for Scan Applications.
    </description>
  </property>

  <property>
    <name>app.exec.threads</name>
    <value>20</value>
    <description>
      Number of Netty service executor threads
    </description>
  </property>

  <property>
    <name>app.worker.threads</name>
    <value>10</value>
    <description>
      Number of Netty service worker threads
    </description>
  </property>


  <!-- Kafka Server Configuration -->

  <property>
    <name>kafka.seed.brokers</name>
    <value>127.0.0.1:9092</value>
    <description>
      Comma-separated list of CDAP Kafka service brokers; for Distributed
      CDAP, replace with list of FQDN:port brokers
    </description>
  </property>

  <property>
    <name>kafka.server.default.replication.factor</name>
    <value>1</value>
    <description>
      CDAP Kafka service replication factor; used to replicate Kafka
      messages across multiple machines to prevent data loss in the event of
      a hardware failure. The recommended setting is to run at least two
      CDAP Kafka servers. If you are running two CDAP Kafka servers, set
      this value to 2; otherwise, set it to the maximum number of tolerated
      machine failures plus one (assuming you have that number of machines).
    </description>
  </property>

  <property>
    <name>kafka.server.host.name</name>
    <value>0.0.0.0</value>
    <description>
      CDAP Kafka service bind address
    </description>
  </property>

  <property>
    <name>kafka.server.log.dirs</name>
    <value>/tmp/kafka-logs</value>
    <description>
      Comma-separated list of CDAP Kafka service log storage directories
    </description>
  </property>

  <property>
    <name>kafka.server.log.flush.interval.messages</name>
    <value>10000</value>
    <description>
      The interval length (in number of messages in the CDAP Kafka service)
      at which to force an fsync of data written to the log
    </description>
  </property>

  <property>
    <name>kafka.server.log.retention.hours</name>
    <value>24</value>
    <description>
      The number of hours to keep a log file before deleting it; this is the
      time-to-live in the CDAP Kafka service, while a log is in-flight
      between the container and the CDAP log saver
    </description>
  </property>

  <property>
    <name>kafka.server.num.partitions</name>
    <value>10</value>
    <description>
      Default number of partitions for a topic in the CDAP Kafka service
    </description>
  </property>

  <property>
    <name>kafka.server.port</name>
    <value>9092</value>
    <description>
      CDAP Kafka service bind port
    </description>
  </property>

  <property>
    <name>kafka.server.zookeeper.connection.timeout.ms</name>
    <value>1000000</value>
    <description>
      Maximum time in milliseconds that the CDAP Kafka service will wait to
      establish a connection to ZooKeeper
    </description>
  </property>

  <property>
    <name>kafka.zookeeper.namespace</name>
    <value>kafka</value>
    <description>
      CDAP Kafka service ZooKeeper namespace
    </description>
  </property>

  <property>
    <name>kafka.zookeeper.quorum</name>
    <value></value>
    <description>
      CDAP Kafka service ZooKeeper quorum and namespace. If set, this will
      override the ZooKeeper quorum (set by ${zookeeper.quorum}) and the
      ZooKeeper namespace (set by ${kafka.zookeeper.namespace}) when setting
      up a connection to the Kafka service used by CDAP. If the same Kafka
      service ZooKeeper quorum and namespace are shared by multiple CDAP
      instances, each CDAP instance needs to distinguish its Kafka topics
      from those of other CDAP instances with unique values for
      ${log.kafka.topic} and ${metrics.topic.prefix}.
    </description>
  </property>


  <!-- Logging Configuration -->

  <property>
    <name>log.base.dir</name>
    <value>/logs/avro</value>
    <description>
      In Distributed CDAP, the HDFS directory under which the system log pipeline saves
      log files
    </description>
  </property>

  <property>
    <name>log.buffer.base.dir</name>
    <value>${local.data.dir}/logs.buffer</value>
    <description>
      Base directory for logs buffer
    </description>
  </property>

  <property>
    <name>log.buffer.max.file.size.bytes</name>
    <value>104857600</value>
    <description>
      Maximum size in bytes of a log buffer file
    </description>
  </property>

  <property>
    <name>log.buffer.server.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Log buffer HTTP service bind address
    </description>
  </property>

  <property>
    <name>log.buffer.server.bind.port</name>
    <value>0</value>
    <description>
      Log buffer HTTP service bind port
    </description>
  </property>

  <property>
    <name>app.program.log.appender.extensions.dir</name>
    <value>/opt/cdap/master/ext/log/appenders</value>
    <description>
      Directory for log appender jars
    </description>
  </property>

  <property>
    <name>app.program.log.appender.provider</name>
    <value></value>
    <description>
      Provider for log appender. The log appender provided by this provider will be loaded in each program container
    </description>
  </property>

  <property>
    <name>app.program.log.appender.provisioners</name>
    <value>native</value>
    <description>
      Comma-separated list of provisioners to enable log appender provider for program executions
    </description>
  </property>

  <property>
    <name>log.buffer.recovery.batch.size</name>
    <value>5000</value>
    <description>
      Log buffer recovery batch size in number of log events read. This will be used to recover logs in batches from
      log buffer upon log service restart
    </description>
  </property>

  <property>
    <name>log.kafka.topic</name>
    <value>logs.user-v2</value>
    <description>
      Kafka topic name used to publish logs
    </description>
  </property>

  <property>
    <name>log.tms.topic.prefix</name>
    <value>logs</value>
    <description>
      TMS topic prefix used to publish logs
    </description>
  </property>

  <property>
    <name>log.queue.size</name>
    <value>2048</value>
    <description>
      The buffer size used in Log Appender
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.dir.permissions</name>
    <value>700</value>
    <description>
      Permissions used by the system log pipeline when creating directories
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.cleanup.interval.mins</name>
    <value>1440</value>
    <description>
      Time in minutes between runs of the log cleanup thread
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.cleanup.batch.size</name>
    <value>10000</value>
    <description>
      Batch size to clean up log metadata table
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.max.lifetime.ms</name>
    <value>21600000</value>
    <description>
      Maximum time span in milliseconds of a log file created by the system log pipeline
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.max.size.bytes</name>
    <value>104857600</value>
    <description>
      Maximum size in bytes of a log file created by the system log pipeline
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.permissions</name>
    <value>600</value>
    <description>
      Permissions used by the system log pipeline when creating files
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.retention.duration.days</name>
    <value>7</value>
    <description>
      Time in days a log file is retained
    </description>
  </property>

  <property>
    <name>log.pipeline.cdap.file.sync.interval.bytes</name>
    <value>10485760</value>
    <description>
      Number of bytes for the sync interval setting of the Avro file written
      by the system log pipeline
    </description>
  </property>

  <property>
    <name>log.process.pipeline.auto.buffer.ratio</name>
    <value>0.7</value>
    <description>
      The ratio of total memory used for determining processing pipeline
      buffer size. This property is only used if
      ${log.process.pipeline.buffer.size} is set to zero and this value
      should be greater than zero and less than one.
    </description>
  </property>

  <property>
    <name>log.process.pipeline.buffer.size</name>
    <value>0</value>
    <description>
      The internal buffer size in bytes for each log processing pipeline.
      Setting it to zero means the system will determine it dynamically
      based on the container size as given by
      ${log.saver.container.memory.mb}.
    </description>
  </property>

  <property>
    <name>log.process.pipeline.checkpoint.interval.ms</name>
    <value>10000</value>
    <description>
      The time between log processing pipeline checkpoints in milliseconds
    </description>
  </property>

  <property>
    <name>log.process.pipeline.config.dir</name>
    <value>/opt/cdap/master/ext/logging/config</value>
    <description>
      A local directory on the CDAP Master that is scanned for log
      processing pipeline configurations. Each pipeline is defined by a file
      in the logback XML format, with ".xml" as the file name extension.
    </description>
  </property>

  <property>
    <name>log.process.pipeline.event.delay.ms</name>
    <value>2000</value>
    <description>
      The time a log event stays in the log processing pipeline buffer
      before writing out to log appenders in milliseconds. A longer delay
      will result in better time ordering of log events before presenting to
      log appenders but will consume more memory.
    </description>
  </property>

  <property>
    <name>log.process.pipeline.kafka.fetch.size</name>
    <value>1048576</value>
    <description>
      The buffer size in bytes, per topic partition, for fetching log events
      from Kafka
    </description>
  </property>

  <property>
    <name>log.process.pipeline.lib.dir</name>
    <value>/opt/cdap/master/ext/logging/lib</value>
    <description>
      Comma-separated list of local directories on the CDAP Master
      scanned for additional library JAR files to be included for log
      processing
    </description>
  </property>

  <property>
    <name>log.process.pipeline.logger.cache.expiration.ms</name>
    <value>300000</value>
    <description>
      Logger cache entry expiration time in milliseconds
    </description>
  </property>

  <property>
    <name>log.process.pipeline.logger.cache.size</name>
    <value>1000</value>
    <description>
      The number of loggers that each log processing pipeline will cache
    </description>
  </property>

  <property>
    <name>log.publish.num.partitions</name>
    <value>10</value>
    <description>
      Number of CDAP Kafka service partitions to publish the logs to
    </description>
  </property>

  <property>
    <name>log.publish.partition.key</name>
    <value>program</value>
    <description>
      Publish logs from an application or a program to the same partition.
      Valid values are "application" or "program". If set to "application",
      logs from all the programs of an application go to the same partition.
      If set to "program", logs from the same program go to the same
      partition. Changes to this property requires restarting of all CDAP
      applications.
    </description>
  </property>

  <property>
    <name>log.query.server.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Log query HTTP service bind address
    </description>
  </property>

  <property>
    <name>log.query.server.bind.port</name>
    <value>0</value>
    <description>
      Log query HTTP service bind port
    </description>
  </property>

  <property>
    <name>log.saver.container.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each log saver instance to run in YARN.
    </description>
  </property>

  <property>
    <name>log.saver.container.num.cores</name>
    <value>2</value>
    <description>
      Number of virtual cores for each log saver instance in YARN
    </description>
  </property>

  <property>
    <name>log.saver.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of log saver instances to run in YARN
    </description>
  </property>

  <property>
    <name>log.saver.num.instances</name>
    <value>1</value>
    <description>
      Number of log saver instances to run in YARN
    </description>
  </property>

  <property>
    <name>log.saver.status.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Log saver HTTP service bind address
    </description>
  </property>


  <!-- Market Configuration -->

  <property>
    <name>market.base.url</name>
    <value>https://hub.cdap.io/v2</value>
    <description>
      The base URL of the Cask Market used by the CDAP UI for the Cask
      Market RESTful API. The default value shown is that of the public Cask
      Market.
    </description>
  </property>


  <!-- Master Configuration -->

  <property>
    <name>twill.runner.service.monitor.disable</name>
    <value>SystemWorkerTwillRunnable</value>
    <description>
      Comma separated list of Twill Runnable classes which start KubeTwillRunnerService, but wants its monitoring to
      be disabled.
    </description>
  </property>

  <property>
    <name>hbase.client.retries.number</name>
    <value>2</value>
    <description>
      Maximum number of retries while performing HBase operations from
      master services
    </description>
  </property>

  <property>
    <name>hbase.rpc.timeout</name>
    <value>15000</value>
    <description>
      RPC timeout from HBase operations performed from master services
    </description>
  </property>

  <property>
    <name>hbase.version.resolution.strategy</name>
    <value>auto.strict</value>
    <description>
      Determines how to behave when the HBase version on a cluster is an unsupported
      value. The default value of "auto.strict" will require that the HBase version match
      a supported value, and CDAP Master will not start if the HBase version is
      unsupported. Set to "auto.latest" to use the latest HBase version available on the
      cluster with an unsupported HBase version.
    </description>
  </property>

  <property>
    <name>http.service.boss.threads</name>
    <value>1</value>
    <description>
      Number of Netty service boss threads for master HTTP services
    </description>
  </property>

  <property>
    <name>http.service.connection.backlog</name>
    <value>20000</value>
    <description>
      Maximum connection backlog of master HTTP service
    </description>
  </property>

  <property>
    <name>http.service.exec.threads</name>
    <value>20</value>
    <description>
      Number of Netty service executor threads for master HTTP services
    </description>
  </property>

  <property>
    <name>http.service.worker.threads</name>
    <value>10</value>
    <description>
      Number of Netty service worker threads for master HTTP services
    </description>
  </property>

  <property>
    <name>master.collect.app.containers.log.level</name>
    <value>ERROR</value>
    <description>
      The log level of application container logs that are streamed back to
      the CDAP Master process log. The levels supported are "ALL", "TRACE",
      "DEBUG", "INFO", "WARN", "ERROR", and "OFF".
    </description>
  </property>

  <property>
    <name>master.collect.containers.log</name>
    <value>true</value>
    <description>
      Determines if master service container logs are streamed back to the
      CDAP Master process log
    </description>
  </property>

  <property>
    <name>master.service.max.instances</name>
    <value>5</value>
    <description>
      Maximum number of master service instances
    </description>
  </property>

  <property>
    <name>master.service.memory.mb</name>
    <value>1024</value>
    <description>
      Macro property to set the default memory in megabytes for each CDAP
      system container
    </description>
  </property>

  <property>
    <name>master.service.num.cores</name>
    <value>2</value>
    <description>
      Number of virtual cores for each master service instance
    </description>
  </property>

  <property>
    <name>master.services.scheduler.queue</name>
    <value></value>
    <description>
      Scheduler queue for CDAP Master services
    </description>
  </property>

  <property>
    <name>master.startup.service.timeout.seconds</name>
    <value>600</value>
    <description>
      Timeout in seconds for master services to wait for their dependent
      services to be available. For example, the dataset executor master
      service requires the transaction service, and will wait for the
      transaction service to become available while it is starting up. If
      the timeout is hit, the service will fail to start and the master
      service will shut itself down. If set to 0 or below, master services
      will not wait for their dependent services to start before starting
      themselves.
    </description>
  </property>


  <!-- Messaging System Configuration -->

  <property>
    <name>messaging.cache.size.mb</name>
    <value>30</value>
    <description>
      Memory in megabytes for the cache size used by the messaging service
      for caching recently-published messages. Currently, only topics listed
      in the ${messaging.system.topics} configuration have caching enabled.
      Set it to 0 to disable caching.
    </description>
  </property>

  <property>
    <name>messaging.container.instances</name>
    <value>1</value>
    <description>
      Number of instances for the messaging service
    </description>
  </property>

  <property>
    <name>messaging.container.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each messaging service instance
    </description>
  </property>

  <property>
    <name>messaging.container.num.cores</name>
    <value>${master.service.num.cores}</value>
    <description>
      Number of virtual cores for each messaging service instance
    </description>
  </property>

  <property>
    <name>messaging.coprocessor.metadata.cache.expiration.seconds</name>
    <value>120</value>
    <description>
      Number of seconds after which the metadata cache in HBase data table
      coprocessors will expire
    </description>
  </property>

  <property>
    <name>messaging.ha.fencing.delay.seconds</name>
    <value>5</value>
    <description>
      Number of seconds to wait before the leader process start serving requests
    </description>
  </property>

  <property>
    <name>messaging.hbase.max.scan.threads</name>
    <value>96</value>
    <description>
      Maximum number of threads used for scanning HBase tables
    </description>
  </property>

  <property>
    <name>messaging.hbase.scan.cache.rows</name>
    <value>1000</value>
    <description>
      Number of rows for caching that will be passed to HBase scanners.
      Higher caching values will enable faster scanning but will use more
      memory.
    </description>
  </property>

  <property>
    <name>messaging.http.compress.payload</name>
    <value>true</value>
    <description>
      Compress payload for HTTP calls in the messaging system
    </description>
  </property>

  <property>
    <name>messaging.http.server.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Messaging HTTP server bind address
    </description>
  </property>

  <property>
    <name>messaging.http.server.bind.port</name>
    <value>0</value>
    <description>
      Messaging HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>messaging.http.server.consume.chunk.size</name>
    <value>60000</value>
    <description>
      Approximate size in bytes of each chunk streamed back to a consumer
    </description>
  </property>

  <property>
    <name>messaging.http.server.executor.threads</name>
    <value>0</value>
    <description>
      Number of executor threads for the HTTP server in the messaging
      system. If set to 0, no executor threads will be used and requests
      will be handled directly in the IO thread.
    </description>
  </property>

  <property>
    <name>messaging.http.server.max.request.size.mb</name>
    <value>10</value>
    <description>
      Maximum request content size in megabytes for each request to the HTTP
      server in the messaging system
    </description>
  </property>

  <property>
    <name>messaging.http.server.worker.threads</name>
    <value>30</value>
    <description>
      Number of IO threads used by the HTTP server in the messaging system
    </description>
  </property>

  <property>
    <name>messaging.local.data.cleanup.frequency.secs</name>
    <value>3600</value>
    <description>
      Scheduling frequency of time-to-live cleanup thread in seconds (only
      used in CDAP Local Sandbox)
    </description>
  </property>

  <property>
    <name>messaging.local.data.dir</name>
    <value>${local.data.dir}/messaging</value>
    <description>
      Local storage directory for the messaging system (used only in
      CDAP Local Sandbox)
    </description>
  </property>

  <property>
    <name>messaging.local.data.partition.secs</name>
    <value>86400</value>
    <description>
      Size of each local messaging table partition in seconds.
    </description>
  </property>

  <property>
    <name>messaging.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of instances for the messaging service.
      Increasing the number of messaging service instances only improves availability, but not scalability
    </description>
    <final>true</final>
  </property>

  <property>
    <name>messaging.message.table.hbase.splits</name>
    <value>16</value>
    <description>
      Number of splits to use for the message table in HBase upon table
      creation
    </description>
  </property>

  <property>
    <name>messaging.message.table.name</name>
    <value>tms.message</value>
    <description>
      Name of the message table of the messaging system
    </description>
  </property>

  <property>
    <name>messaging.metadata.table.name</name>
    <value>tms.meta</value>
    <description>
      Name of the metadata table of the messaging system
    </description>
  </property>

  <property>
    <name>messaging.payload.table.hbase.splits</name>
    <value>16</value>
    <description>
      Number of splits to use for the payload table in HBase upon table
      creation
    </description>
  </property>

  <property>
    <name>messaging.payload.table.name</name>
    <value>tms.payload</value>
    <description>
      Name of the payload table of the messaging system
    </description>
  </property>

  <property>
    <name>messaging.system.topics</name>
    <value>${audit.topic},${metadata.messaging.topic},${data.event.topic},${metrics.topic.prefix}:${metrics.messaging.topic.num},${metrics.admin.topic},${time.event.topic},${program.status.event.topic},${program.status.record.event.topic},${log.tms.topic.prefix}:${log.publish.num.partitions},${preview.messaging.topic},previewlog0</value>
    <description>
      A comma-separated list of topics that are always available in the
      system namespace. Multiple topics sharing the same prefix and
      distinguished by different numerical suffixes can be specified with
      the syntax &lt;common.prefix&gt;:&lt;total.topic.number&gt;, where the
      &lt;total.topic.number&gt; is the total number of topics sharing the
      &lt;common.prefix&gt;, and the numerical suffixes will range from 0 to
      (&lt;total.topic.number&gt; - 1).
    </description>
    <final>true</final>
  </property>

  <property>
    <name>messaging.table.expiration.seconds</name>
    <value>300</value>
    <description>
      Number of seconds after which the messaging table cache will expire
    </description>
  </property>

  <property>
    <name>messaging.table.hbase.split.policy</name>
    <value>org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy</value>
    <description>
      The class name that controls the HBase table region split policy.
      Ideally, auto-splitting should be disabled for HBase tables used by the messaging system.
    </description>
  </property>

  <property>
    <name>messaging.topic.default.ttl.seconds</name>
    <value>604800</value>
    <description>
      The default time-to-live in seconds for messages in a topic
    </description>
  </property>

  <property>
    <!-- Use lower heap memory ratio for the messaging service, since it uses non-heap memory for the connections -->
    <name>messaging.twill.java.heap.memory.ratio</name>
    <value>0.6</value>
    <description>
      The minimum ratio of heap to non-heap memory for the messaging service container
    </description>
  </property>

  <property>
    <!-- Use higher reserved memory setting for the messaging service, since it uses non-heap memory for connections -->
    <name>messaging.twill.java.reserved.memory.mb</name>
    <value>512</value>
    <description>
      Desired reserved non-heap memory in megabytes for the messaging service container.
      The actual value is bounded by the ${twill.java.heap.memory.ratio} setting of the container memory size.
    </description>
  </property>


  <!-- Metadata Configuration -->

  <property>
    <name>metadata.max.allowed.chars</name>
    <value>50</value>
    <description>
      Maximum number of characters for metadata keys, values, and tags
    </description>
  </property>

  <property>
    <name>metadata.service.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Metadata HTTP service bind address
    </description>
  </property>

  <property>
    <name>metadata.service.bind.port</name>
    <value>0</value>
    <description>
      Metadata HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>metadata.service.exec.threads</name>
    <value>${http.service.exec.threads}</value>
    <description>
      Number of Netty service executor threads for metadata HTTP service
    </description>
  </property>

  <property>
    <name>metadata.service.worker.threads</name>
    <value>${http.service.worker.threads}</value>
    <description>
      Number of Netty service IO worker threads for metadata HTTP service
    </description>
  </property>

  <property>
    <name>metadata.messaging.topic</name>
    <value>metadata</value>
    <description>
      Topic name used to publish metadata messages in the messaging system
    </description>
  </property>

  <property>
    <name>metadata.messaging.fetch.size</name>
    <value>100</value>
    <description>
      Number of messages to fetch from messaging system for each batch
    </description>
  </property>

  <property>
    <name>metadata.messaging.poll.delay.millis</name>
    <value>2000</value>
    <description>
      The delay in milliseconds that the lineage processor checks again for
      new events after it detects there was no event
    </description>
  </property>

  <property>
    <name>metadata.messaging.retries.on.conflict</name>
    <value>100</value>
    <description>
      The maximal number of times a metadata message will be processed if it
      repeatedly causes a conflict exception. After this, the mesaage will be
      discarded.
    </description>
  </property>

  <property>
    <name>metadata.messaging.publish.size.limit</name>
    <value>2147483647</value>
    <description>
      The maximum number of characters for a JSON string representation of a
      lineage to be published. If the lineage exceeds this size it will not be
      published.
    </description>
  </property>

  <!-- Metrics Configuration -->

  <property>
    <name>metrics.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Metrics query HTTP service bind address
    </description>
  </property>

  <property>
    <name>metrics.bind.port</name>
    <value>0</value>
    <description>
      Metrics query HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>metrics.boss.threads</name>
    <value>${http.service.boss.threads}</value>
    <description>
      Number of Netty service boss threads for metrics HTTP services
    </description>
  </property>

  <property>
    <name>metrics.connection.backlog</name>
    <value>${http.service.connection.backlog}</value>
    <description>
      Maximum connection backlog of metrics HTTP service
    </description>
  </property>

  <property>
    <name>metrics.minimum.resolution.seconds</name>
    <value>1</value>
    <description>
      Minimum metrics resolution in seconds, this value should be less than 60 seconds, otherwise the minimum metrics
      resolution will be 60 seconds.
    </description>
  </property>

  <property>
    <name>metrics.data.table.retention.minimum.resolution.seconds</name>
    <value>7200</value>
    <description>
      Retention resolution in seconds of the minimum resolution table;
      default retention period is 2 hours, this retention will not be applied if the
      minimum resolution is greater than or equal to 60.
    </description>
  </property>

  <property>
    <name>metrics.data.table.retention.resolution.3600.seconds</name>
    <value>2592000</value>
    <description>
      Retention resolution in seconds of the 1-hour resolution table;
      default retention period is 30 days
    </description>
  </property>

  <property>
    <name>metrics.data.table.retention.resolution.60.seconds</name>
    <value>2592000</value>
    <description>
      Retention resolution in seconds for the 1-minute resolution table;
      default retention period is 30 days
    </description>
  </property>

  <property>
    <name>metrics.data.table.ts.rollTime.3600</name>
    <value>24</value>
    <description>
      Number of columns in a 1-hour resolution timeseries table
    </description>
  </property>

  <property>
    <name>metrics.data.table.ts.rollTime.60</name>
    <value>60</value>
    <description>
      Number of columns in a 1-minute resolution timeseries table
    </description>
  </property>

  <property>
    <name>metrics.data.coarse.lag.factor</name>
    <value>12</value>
    <description>
      Resolution-based factor that defines wall clock lag. After incoming metrics processing delay reaches this lag,
      metrics will be aggregated to bigger inteval based on round factor. E.g. for resolution of 5 seconds and
      lag factor of 12, coarsing will be done for any metrics that are more than 5*12=60 seconds late.
    </description>
  </property>

  <property>
    <name>metrics.data.coarse.round.factor</name>
    <value>20</value>
    <description>
      Resolution-based factor that defines increased interval at which metrics will be stored after coarsing kicked
      in based on lag factor. E.g. for resolution of 5 seconds and round factor of 20, metrics will be stored
      each 5*20=100 seconds instead of each 5 seconds. They will still be stored in the same 5 second table, so
      table users don't need to be changed, they would just see data at more rare timestamps. The only quirk here
      is that now data can be attributed to the moment up to 99 seconds earlier and not 5 seconds earlier than it was
      produced due to a higher rounding involved. This mechanism allows to handle overload more gracefully.
    </description>
  </property>

  <property>
    <name>metrics.dataset.hbase.stats.report.interval</name>
    <value>60</value>
    <description>
      Report interval in seconds for HBase stats
    </description>
  </property>

  <property>
    <name>metrics.dataset.leveldb.stats.report.interval</name>
    <value>60</value>
    <description>
      Report interval in seconds for LevelDB stats
    </description>
  </property>

  <property>
    <name>metrics.data.table.write.parallelism</name>
    <value>5</value>
    <description>
      Controls parallel computations and writes to each resolution metrics table. While write itself is guarded
      by a mutex, pre-write computations and aggregations takes time, so it makes sense to do it in parallel.
    </description>
  </property>

  <property>
    <name>metrics.exec.threads</name>
    <value>${http.service.exec.threads}</value>
    <description>
      Number of Netty service executor threads for metrics HTTP services
    </description>
  </property>

  <property>
    <name>metrics.meta.table</name>
    <value>metrics.meta</value>
    <description>
      Name of the metrics meta table
    </description>
  </property>

  <property>
    <name>metrics.kafka.partition.size</name>
    <value>10</value>
    <description>
      Number of partitions for the Kafka metrics topic
    </description>
  </property>

  <property>
    <name>metrics.kafka.topic.prefix</name>
    <value>metrics</value>
    <description>
      Topic prefix used to publish metrics in Kafka
    </description>
  </property>

  <property>
    <name>metrics.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of instances for the metrics service
    </description>
  </property>

  <property>
    <name>metrics.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each metrics service instance
    </description>
  </property>

  <property>
    <name>metrics.messaging.meta.table</name>
    <value>metrics.messaging.meta</value>
    <description>
      Name of the messaging metrics meta table
    </description>
  </property>

  <property>
    <name>metrics.messaging.topic.num</name>
    <value>10</value>
    <description>
      Number of topics for metrics messages. This property also sets the
      number of threads used to fetch and process metrics in parallel from
      the messaging service. For a value of N, topics will be created for
      metrics with names beginning at ${metrics.topic.prefix}0,
      ${metrics.topic.prefix}1, up to ${metrics.topic.prefix}(N-1).
    </description>
  </property>

  <property>
    <name>metrics.num.cores</name>
    <value>${master.service.num.cores}</value>
    <description>
      Number of virtual cores for the metrics service
    </description>
  </property>

  <property>
    <name>metrics.num.instances</name>
    <value>1</value>
    <description>
      Number of instances for the metrics service
    </description>
  </property>

  <property>
    <name>metrics.processor.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of instances for metrics processor service Apache Twill
      runnable
    </description>
  </property>

  <property>
    <name>metrics.processor.memory.mb</name>
    <value>${master.service.memory.mb}</value>
    <description>
      Memory in megabytes for each metrics processor service Apache Twill
      runnable instance
    </description>
  </property>

  <property>
    <name>metrics.processor.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for metrics processor service Apache Twill
      runnable
    </description>
  </property>

  <property>
    <name>metrics.processor.num.instances</name>
    <value>1</value>
    <description>
      Number of instances for metrics processor service Apache Twill
      runnable
    </description>
  </property>

  <property>
    <name>metrics.processor.status.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Metrics processor HTTP service bind address
    </description>
  </property>

  <property>
    <name>metrics.processor.status.bind.port</name>
    <value>0</value>
    <description>
      Metrics processor HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>metrics.topic.prefix</name>
    <value>metrics</value>
    <description>
      Topic prefix used to publish metrics in messaging
    </description>
  </property>

  <property>
    <name>metrics.admin.topic</name>
    <value>metricsadmin</value>
    <description>
      Topic name for publishing metrics administrative events to the messaging system
    </description>
  </property>

  <property>
    <name>metrics.admin.poll.delay.millis</name>
    <value>2000</value>
    <description>
      The delay in milliseconds to check again for new metrics administrative events after it detects there was no event
    </description>
  </property>

  <property>
    <name>metrics.worker.threads</name>
    <value>${http.service.worker.threads}</value>
    <description>
      Number of Netty service worker threads for metrics HTTP services
    </description>
  </property>

  <property>
    <name>metrics.processor.queue.size</name>
    <value>1000</value>
    <description>
      Maximum size of a queue where the metrics processor temporarily stores
      newly-fetched metrics in-memory before persisting them
    </description>
  </property>

  <property>
    <name>metrics.processor.offer.timeout.ms</name>
    <value>10000</value>
    <description>
      How long to wait for queue to be able to accept newly-fetched metrics before giving up
    </description>
  </property>

  <property>
    <name>metrics.processor.max.delay.ms</name>
    <value>3000</value>
    <description>
      Maximum delay in milliseconds allowed between the latest metrics timestamp and the
      time when it is processed
    </description>
  </property>

  <property>
    <name>app.program.metrics.enabled</name>
    <value>true</value>
    <description>
      Enable or disable emitting metrics from user application programs, by default set to true.
    </description>
  </property>

  <property>
    <name>app.program.spark.metrics.enabled</name>
    <value>false</value>
    <description>
      Enable or disable emitting spark-specific metrics, by default set to false.
      Note that spark-specific metrics are very resource consuming and are deprecated. If you need spark metrics
      it's better to use data from spark history server.
    </description>
  </property>

  <property>
    <name>metrics.hbase.max.scan.threads</name>
    <value>96</value>
    <description>
      Maximum number of threads used for scanning HBase tables
    </description>
  </property>

  <property>
    <name>metrics.table.splits</name>
    <value>16</value>
    <description>
      Number of splits for all metrics tables. This property can only be changed before CDAP starts up for the first
      time and creates the metrics tables. Once all metrics tables are created, this property will not take any effect.
    </description>
  </property>

  <property>
    <name>metrics.table.hbase.split.policy</name>
    <value>org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy</value>
    <description>
      The class name that controls the HBase table region split policy.
      Ideally, auto-splitting should be disabled for HBase tables used by the metrics system.
    </description>
  </property>

  <property>
    <name>structured.table.time.metrics.enabled</name>
    <value>false</value>
    <description>
      Option to turn on the time metrics for the structured table operations.
    </description>
  </property>

  <!-- Monitor Handler Configuration -->

  <property>
    <name>monitor.handler.service.discovery.timeout.seconds</name>
    <value>1</value>
    <description>
      Timeout in seconds for service discovery used in monitor handler
      service status check
    </description>
  </property>

  <property>
    <name>metadata.consumer.extensions.dir</name>
    <value>/opt/cdap/master/ext/metadataconsumers</value>
    <description>
      Semicolon-separated list of local directories on the CDAP Master that
      are scanned for metadata consumer extensions
    </description>
  </property>

  <property>
    <name>metadata.consumer.extensions.enabled.list</name>
    <value></value>
    <description>
      Comma separated list of metadata consumer extension names that are enabled.
      Extensions that are not present in this list will be ignored.
    </description>
  </property>

  <property>
    <name>metrics.writer.extensions.dir</name>
    <value>/opt/cdap/master/ext/metricswriters</value>
    <description>
      Semicolon-separated list of local directories on the CDAP Master that
      are scanned for metrics writer extensions
    </description>
  </property>

  <property>
    <name>metrics.writer.extensions.enabled.list</name>
    <value></value>
    <description>
      Comma separated list of metric writer extension names that are enabled.
      Extensions that are not present in this list will be ignored.
    </description>
  </property>

  <!-- Provisioner Configuration -->
  <property>
    <name>provisioner.executor.threads</name>
    <value>10</value>
    <description>
      Thread pool size for the executor in the provisioning service
    </description>
  </property>

  <property>
    <name>provisioner.context.executor.threads</name>
    <value>10</value>
    <description>
      Maximum number of threads for the provisioning context executor.
      It is used by the provisioner implementation to perform task asynchronously.
    </description>
  </property>


  <!-- Runtime Monitor Configuration -->

  <property>
    <name>app.program.runtime.monitor.polltime.ms</name>
    <value>2000</value>
    <description>
      Polling time in milliseconds to poll updates from a runtime
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.batch.size</name>
    <value>1000</value>
    <description>
      Number of events to fetch from a runtime in each poll call
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.compression.enabled</name>
    <value>true</value>
    <description>
      Enable compression for runtime monitoring traffic
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.topics.configs</name>
    <value>audit.topic,data.event.topic,metadata.messaging.topic,metrics.topic.prefix:${metrics.messaging.topic.num},program.status.event.topic,log.tms.topic.prefix:${log.publish.num.partitions}</value>
    <description>
      A comma-separated list of topic config to be monitored by runtime monitor
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.graceful.shutdown.ms</name>
    <value>30000</value>
    <description>
      Number of milliseconds to wait for the runtime to shutdown after a program execution completed in that runtime.
      This value should be larger than the value of the "app.program.runtime.monitor.polltime.ms" property
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.initialize.batch.size</name>
    <value>100</value>
    <description>
      Number of runtime states to fetch from dataset in each batch during runtime monitor initialization.
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.run.record.fetch.class</name>
    <value>io.cdap.cdap.internal.app.store.StoreProgramRunRecordFetcher</value>
    <description>
      Class name of the ProgramRunRecordFetcher used by the runtime monitoring system.
      This value controls the run record fetching mechanism depending on the CDAP setup.
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.server.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      The address for the runtime monitor server to bind to.
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.server.bind.port</name>
    <value>0</value>
    <description>
      The port the runtime monitor server to bind to.
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.server.ssl.enabled</name>
    <value>${ssl.internal.enabled}</value>
    <description>
      Enable usage of SSL for the runtime monitor server. By default is disabled.
      This is because traffic is already encrypted through the SSH tunnel.
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.server.info.file</name>
    <value>runtime.monitor.server.info</value>
    <description>
      File name for the runtime monitor to store the port number.
      This configuration is for internal use only and should not be changed.
    </description>
    <final>true</final>
  </property>

  <property>
    <name>app.program.runtime.monitor.server.consume.chunk.size</name>
    <value>60000</value>
    <description>
      Approximate size in bytes of each chunk streamed back to Runtime Monitor client
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.threads</name>
    <value>20</value>
    <description>
      Maximum number of threads being used by runtime monitor for runtime monitoring
    </description>
  </property>

  <property>
    <name>app.program.runtime.monitor.audit.log.enabled</name>
    <value>${security.enabled}</value>
    <description>
      Determine if access audit log is enabled
    </description>
  </property>

  <property>
    <name>system.runtime.monitor.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.runtime.monitor.retry.policy.max.delay.ms</name>
    <value>1000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.runtime.monitor.retry.policy.max.retries</name>
    <value>2147483647</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.runtime.monitor.retry.policy.max.time.secs</name>
    <value>3600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.runtime.monitor.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for log processing. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Operational Statistics Configuration -->

  <property>
    <name>operational.stats.extensions.dir</name>
    <value>/opt/cdap/master/ext/operations</value>
    <description>
      Semicolon-separated list of local directories on the CDAP Master that
      are scanned for operational statistics extensions
    </description>
  </property>

  <property>
    <name>operational.stats.refresh.interval.secs</name>
    <value>60</value>
    <description>
      Number of seconds after which operational statistics should be
      refreshed
    </description>
  </property>

  <!-- Runtime Configuration -->

  <property>
    <name>runtime.extensions.dir</name>
    <value>/opt/cdap/master/ext/runtimeproviders</value>
    <description>
      Semicolon-separated list of local directories on the CDAP Master that
      are scanned for program runtime extensions
    </description>
  </property>

  <!-- Queue Configuration -->

  <property>
    <name>data.queue.config.update.interval</name>
    <value>5</value>
    <description>
      Frequency in seconds of updates to the queue consumer configuration
      used in evicting queue entries on flush and compaction
    </description>
  </property>

  <property>
    <name>data.queue.dequeue.tx.percent</name>
    <value>30</value>
    <description>
      Percentage of transaction time allowed to spend in dequeue; it should
      be an integer between 1-100
    </description>
  </property>

  <property>
    <name>data.queue.table.presplits</name>
    <value>16</value>
    <description>
      Number of splits in the queue table
    </description>
  </property>


  <!-- Remote System Operation Configuration -->

  <property>
    <name>remote.system.op.exec.threads</name>
    <value>${http.service.exec.threads}</value>
    <description>
      Number of Netty service executor threads for the remote system
      operation HTTP service
    </description>
  </property>

  <property>
    <name>remote.system.op.service.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      Remote system operation HTTP service bind address
    </description>
  </property>

  <property>
    <name>remote.system.op.worker.threads</name>
    <value>${http.service.worker.threads}</value>
    <description>
      Number of Netty service IO worker threads for the remote system
      operation HTTP service
    </description>
  </property>


  <!-- Retry Policies Configuration -->

  <property>
    <name>custom.action.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>custom.action.retry.policy.max.delay.ms</name>
    <value>30000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>custom.action.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>custom.action.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>custom.action.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for custom actions. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>mapreduce.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>mapreduce.retry.policy.max.delay.ms</name>
    <value>30000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>mapreduce.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>mapreduce.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>mapreduce.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for MapReduce programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>preview.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      The bind address for the preview service.
    </description>
  </property>

  <property>
    <name>preview.bind.port</name>
    <value>0</value>
    <description>
      The port to bind the preview service to.
    </description>
  </property>

  <property>
    <name>preview.connection.backlog</name>
    <value>20000</value>
    <description>
      The connection backlog in the CDAP Preview service
    </description>
  </property>

  <property>
    <name>preview.exec.threads</name>
    <value>10</value>
    <description>
      The number of executor threads for the preview service
    </description>
  </property>

  <property>
    <name>preview.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads for the preview service
    </description>
  </property>

  <property>
    <name>preview.worker.threads</name>
    <value>10</value>
    <description>
      The number of worker threads in the CDAP Router service
    </description>
  </property>

  <property>
    <name>preview.request.poll.delay.millis</name>
    <value>2000</value>
    <description>
      The delay in milliseconds to check again for new preview request after it detects there was no request
    </description>
  </property>

  <property>
    <name>preview.max.runs</name>
    <value>0</value>
    <description>
      The maximum number of preview execution per preview runner process. Default is 0 to have no maximum limit.
    </description>
  </property>

  <property>
    <name>preview.data.cleanup.interval.seconds</name>
    <value>3600</value>
    <description>
      Interval in seconds for preview data cleanup process. Default is 1 hr.
    </description>
  </property>

  <property>
    <name>preview.data.ttl.seconds</name>
    <value>86400</value>
    <description>
      TTL for the preview data, by default 1 day
    </description>
  </property>

  <property>
    <name>preview.messaging.topic</name>
    <value>preview</value>
    <description>
      Topic name used to publish preview messages including status, data, and runid to the messaging system
    </description>
  </property>

  <property>
    <name>preview.poller.count</name>
    <value>10</value>
    <description>
      Number of pollers in each preview runner process
    </description>
  </property>

  <property>
    <name>preview.runner.container.disk.size.gb</name>
    <value>10</value>
    <description>
      Size of the stateful disk for the preview runner
    </description>
  </property>

  <property>
    <name>preview.runner.container.count</name>
    <value>0</value>
    <description>
      Number of preview runner containers for preview execution. If it is set to 0, preview execution will be
      running in the same process as the preview manager.
    </description>
  </property>

  <property>
    <name>preview.runner.container.memory.mb</name>
    <value>756</value>
    <description>
      Memory in megabytes for each preview runner container
    </description>
  </property>

  <property>
    <name>preview.runner.container.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for the preview runner
    </description>
  </property>

  <property>
    <name>preview.runner.container.jvm.opts</name>
    <value>-XX:+UseG1GC -XX:+ExitOnOutOfMemoryError</value>
    <description>
      JVM opts for preview runner containers.
    </description>
  </property>

  <property>
    <name>service.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>service.retry.policy.max.delay.ms</name>
    <value>1000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>service.retry.policy.max.retries</name>
    <value>3</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>service.retry.policy.max.time.secs</name>
    <value>10</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>service.retry.policy.type</name>
    <value>none</value>
    <description>
      The type of retry policy for services. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>spark.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>spark.retry.policy.max.delay.ms</name>
    <value>30000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>spark.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>spark.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>spark.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for Spark programs. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>spark.streaming.checkpoint.rewrite.enabled</name>
    <value>true</value>
    <description>
      Specify whether to rewrite the temporary checkpoint file name by adding the checkpoint timestamp to the temporary
      file name. This is useful when using object storage as the checkpoint directory.
    </description>
  </property>

  <property>
    <name>system.log.process.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.log.process.retry.policy.max.retries</name>
    <value>1500</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.log.process.retry.policy.max.time.secs</name>
    <value>1500</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.log.process.retry.policy.type</name>
    <value>fixed.delay</value>
    <description>
      The type of retry policy for log processing. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.metadata.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.metadata.retry.policy.max.delay.ms</name>
    <value>2000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.metadata.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.metadata.retry.policy.max.time.secs</name>
    <value>2147483647</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.metadata.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for workers. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.metrics.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.metrics.retry.policy.max.retries</name>
    <value>600</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.metrics.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.metrics.retry.policy.type</name>
    <value>fixed.delay</value>
    <description>
      The type of retry policy for metrics publishing. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.notification.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.notification.retry.policy.max.delay.ms</name>
    <value>5000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.notification.retry.policy.max.retries</name>
    <value>5000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.notification.retry.policy.max.time.secs</name>
    <value>7200</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.notification.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for notification publish or subscription. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.preview.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.preview.retry.policy.max.delay.ms</name>
    <value>5000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.preview.retry.policy.max.retries</name>
    <value>5000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.preview.retry.policy.max.time.secs</name>
    <value>7200</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.preview.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for notification publish or subscription. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.preview.store.update.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.preview.store.update.retry.policy.max.delay.ms</name>
    <value>5000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.preview.store.update.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.preview.store.update.retry.policy.max.time.secs</name>
    <value>300</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.preview.store.update.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for notification publish or subscription. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>system.program.state.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.program.state.retry.policy.max.delay.ms</name>
    <value>3000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>system.program.state.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>system.program.state.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>system.program.state.retry.policy.type</name>
    <value>fixed.delay</value>
    <description>
      The type of retry policy for programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>worker.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>worker.retry.policy.max.delay.ms</name>
    <value>30000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>worker.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>worker.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>worker.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for workers. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>workflow.retry.policy.base.delay.ms</name>
    <value>1000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>workflow.retry.policy.max.delay.ms</name>
    <value>30000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>workflow.retry.policy.max.retries</name>
    <value>1000</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>workflow.retry.policy.max.time.secs</name>
    <value>600</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>workflow.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for workflows. Allowed options: "none",
      "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Retry configuration for task worker -->
  <!-- Use an exponential delay that cap at 2 seconds interval -->
  <property>
    <name>task.worker.retry.policy.base.delay.ms</name>
    <value>10</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>task.worker.retry.policy.max.delay.ms</name>
    <value>2000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <!-- Set to Integer max value, so the retry attempts end based on task.worker.retry.policy.max.time.secs -->
  <property>
    <name>task.worker.retry.policy.max.retries</name>
    <value>2147483647</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <!-- Set to 60s to match the default http request timeout -->
  <property>
    <name>task.worker.retry.policy.max.time.secs</name>
    <value>60</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>task.worker.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Retry configuration for artifact cache -->
  <!-- Use an exponential delay that cap at 2 seconds interval -->
  <property>
    <name>artifact.cache.retry.policy.base.delay.ms</name>
    <value>10</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>artifact.cache.retry.policy.max.delay.ms</name>
    <value>2000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <!-- Set to Integer max value, so the retry attempts end based on artifact.cache.retry.policy.max.time.secs -->
  <property>
    <name>artifact.cache.retry.policy.max.retries</name>
    <value>2147483647</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <!-- Set to 60s to match the default http request timeout -->
  <property>
    <name>artifact.cache.retry.policy.max.time.secs</name>
    <value>60</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>artifact.cache.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Retry configuration for app state handling -->
  <property>
    <name>app.state.retry.policy.base.delay.ms</name>
    <value>10</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>app.state.retry.policy.max.delay.ms</name>
    <value>2000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <!-- Set to Integer max value, so the retry attempts end based on app.state.retry.policy.max.time.secs -->
  <property>
    <name>app.state.retry.policy.max.retries</name>
    <value>2147483647</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <!-- Set to 60s to match the default http request timeout -->
  <property>
    <name>app.state.retry.policy.max.time.secs</name>
    <value>60</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>app.state.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Retry configuration for spark metrics retrieval -->
  <property>
    <name>spark.metrics.strategy.retry.policy.base.delay.ms</name>
    <value>100</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>spark.metrics.strategy.retry.policy.max.delay.ms</name>
    <value>2000</value>
    <description>
      The maximum delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>spark.metrics.strategy.retry.policy.max.retries</name>
    <value>10</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name> spark.metrics.strategy.retry.policy.max.time.secs</name>
    <value>30</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>spark.metrics.strategy.retry.policy.type</name>
    <value>exponential.backoff</value>
    <description>
      The type of retry policy for programs. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <!-- Router Configuration -->

  <property>
    <name>router.audit.log.enabled</name>
    <value>${security.enabled}</value>
    <description>
      Determine if access audit log is enabled
    </description>
  </property>

  <property>
    <name>router.audit.path.check.enabled</name>
    <value>true</value>
    <description>
      Determines if to check the number of paths for audit logging
    </description>
  </property>

  <property>
    <name>router.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      CDAP Router service bind address
    </description>
  </property>

  <property>
    <name>router.bind.port</name>
    <value>11015</value>
    <description>
      CDAP Router service bind port
    </description>
  </property>

  <property>
    <name>router.cconf.reload.interval.seconds</name>
    <value>0</value>
    <description>
      Interval in seconds at which CDAP Router reloads cconf,
      defaults to 0 which means no reloading should happen
    </description>
  </property>

  <property>
    <name>router.connection.backlog</name>
    <value>20000</value>
    <description>
      The connection backlog in the CDAP Router service
    </description>
  </property>

  <property>
    <name>router.connection.idle.timeout.secs</name>
    <value>15</value>
    <description>
      Time in seconds after an HTTP request completes that idle router
      connections are closed
    </description>
  </property>

  <property>
    <name>router.server.address</name>
    <value>127.0.0.1</value>
    <description>
      CDAP Router service address to which CDAP UI connects
    </description>
  </property>

  <property>
    <name>router.server.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads in the CDAP Router service
    </description>
  </property>

  <property>
    <name>router.server.port</name>
    <value>${router.bind.port}</value>
    <description>
      CDAP Router service port
    </description>
  </property>

  <property>
    <name>router.server.worker.threads</name>
    <value>10</value>
    <description>
      The number of worker threads in the CDAP Router service
    </description>
  </property>

  <property>
    <name>router.ssl.bind.port</name>
    <value>10443</value>
    <description>
      CDAP Router service bind port for HTTPS
    </description>
  </property>

  <property>
    <name>router.ssl.server.port</name>
    <value>${router.ssl.bind.port}</value>
    <description>
      CDAP Router service bind port for HTTPS
    </description>
  </property>

  <property>
    <name>router.ssl.cert.path</name>
    <value></value>
    <description>
      File path to certificate and private key file in PEM format to use for CDAP Router
      when ssl.external.enabled is set to true.
    </description>
  </property>

  <!-- Security Configuration -->

  <property>
    <name>cdap.master.kerberos.keytab</name>
    <value></value>
    <description>
      The full path to the Kerberos keytab file containing the CDAP Master
      service's credentials
    </description>
  </property>

  <property>
    <name>security.authentication.mode</name>
    <value>MANAGED</value>
    <description>
      Determines the mode of authentication to use if security is enabled. Supported modes include MANAGED and PROXY.
      MANAGED mode supports a CDAP-managed authentication server and uses CDAP's access tokens to authenticate the user.
      PROXY mode assumes that authentication has already been performed upstream and instead extracts the user's
      identity and credentials from the configured headers.
    </description>
  </property>

  <property>
    <name>security.authentication.propagate.user.credentials</name>
    <value>false</value>
    <description>
      Determines whether credentials in the Authorization header of requests are propagated from the request router
      to the rest of the backend handlers. Should be false unless the authorization extension requires the end-user
      credential to authorize users.
    </description>
  </property>

  <property>
    <name>security.authentication.proxy.user.identity.header</name>
    <value>CDAP-UserId</value>
    <description>
      The header to extract the user identity from. The user identity header must be provided for PROXY mode to
      function, and CDAP requires that the header must be set on all requests to the backend.
    </description>
  </property>

  <property>
    <name>cdap.master.kerberos.principal</name>
    <value></value>
    <description>
      Example: "CDAP_PRINCIPAL/_HOST@EXAMPLE.COM". The Kerberos primary user
      that should be used to login to the CDAP Master service. Substitute
      the Kerberos primary (user) for CDAP_PRINCIPAL, and your domain for
      EXAMPLE.COM. The string "_HOST" will be substituted with the local
      hostname.
    </description>
  </property>

  <property>
    <name>cdap.ugi.cache.expiration.ms</name>
    <value>3600000</value>
    <description>
      UserGroupInformation cache entry expiration time in milliseconds. It
      is only used when impersonation is enabled.
    </description>
  </property>

  <property>
    <name>kerberos.auth.enabled</name>
    <value>${security.enabled}</value>
    <description>
      Determines if Kerberos authentication is enabled
    </description>
  </property>

  <property>
    <name>kerberos.auth.relogin.interval.seconds</name>
    <value>300</value>
    <description>
      Re-login interval in seconds for Kerberos keytab
    </description>
  </property>

  <property>
    <name>security.auth.server.announce.urls</name>
    <value></value>
    <description>
      CDAP Authentication service announce URL's separated by comma. Each URL is in the format of protocol://host:port.
      These are the URL's that clients should use to communicate with the Authentication Server.
      Leave empty to use the default value generated by the Authentication Server.
    </description>
  </property>

  <property>
    <name>security.auth.server.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      CDAP Authentication service bind address
    </description>
  </property>

  <property>
    <name>security.auth.server.bind.port</name>
    <value>10009</value>
    <description>
      CDAP Authentication service bind port
    </description>
  </property>

  <property>
    <name>security.auth.server.ssl.bind.port</name>
    <value>10010</value>
    <description>
      CDAP Authentication service bind port for HTTPS
    </description>
  </property>

  <property>
    <name>security.authentication.basic.realmfile</name>
    <value></value>
    <description>
      Username and password file to use when basic authentication is
      configured
    </description>
  </property>

  <property>
    <name>security.authentication.handlerClassName</name>
    <value></value>
    <description>
      Name of the authentication implementation to use to validate user
      credentials
    </description>
  </property>

  <property>
    <name>security.authentication.loginmodule.className</name>
    <value></value>
    <description>
      JAAS LoginModule implementation to use when
      io.cdap.security.server.JAASAuthenticationHandler is configured for
      ${security.authentication.handlerClassName}
    </description>
  </property>

  <property>
    <name>security.authorization.cache.max.entries</name>
    <value>150000</value>
    <description>
      Number of entries to hold in the container authorization cache. If set to 0, no
      caching will be performed.
    </description>
  </property>

  <property>
    <name>security.authorization.extension.config.cache.max.entries</name>
    <value>${security.authorization.cache.max.entries}</value>
    <description>
      Number of entries to hold in the container authorization cache. If set to 0, no
      caching will be performed.
    </description>
  </property>

  <property>
    <name>security.authorization.cache.ttl.secs</name>
    <value>300</value>
    <description>
      The time-to-live in seconds for entries in the authorization cache
      used by programs and system services outside of CDAP Master.
    </description>
  </property>

  <property>
    <name>security.authorization.extension.config.cache.ttl.secs</name>
    <value>${security.authorization.cache.ttl.secs}</value>
    <description>
      The time-to-live in seconds for entries in the authorization cache
      used by programs and system services outside of CDAP Master.
    </description>
  </property>

  <property>
    <name>security.authorization.enabled</name>
    <value>false</value>
    <description>
      When set to true, all operations in CDAP are authorized using the
      authorizer implementation found at the property
      ${security.authorization.extension.jar.path}
    </description>
  </property>

  <property>
    <name>security.authorization.extension.jar.path</name>
    <value></value>
    <description>
      If an external authorization system is used for authorizing operations
      on CDAP entities, this property sets the path to the bundled JAR file
      containing the extension code. This jar is only used when
      authorization is enabled by setting ${security.authorization.enabled}
      to true.
    </description>
  </property>

  <property>
    <name>security.authorization.extension.operation.time.warn.threshold.ms</name>
    <value>5000</value>
    <description>
      Time taken by an authorization extension to perform an enforce operation is recorded and
      logged at TRACE level. This property sets the upper limit for the time taken by the extension in milliseconds
      after which it is logged at WARN level rather than TRACE.
    </description>
  </property>

  <property>
    <name>security.data.keyfile.path</name>
    <value>${local.data.dir}/security/keyfile</value>
    <description>
      Path to the secret key file. In distributed CDAP, if the zookeeper.quorum
      properties is overridden, then
      Zookeeper will be used for storing secret key and this property will be ignore.
    </description>
  </property>

  <property>
    <name>security.enabled</name>
    <value>false</value>
    <description>
      Determines if authentication is enabled for CDAP; if true, all
      requests to CDAP must provide a valid access token
    </description>
  </property>

  <property>
    <name>security.keytab.path</name>
    <value></value>
    <description>
      The location of Kerberos keytabs used for impersonation. The location
      can contain ${name}, which will be replaced by the short user name of
      the principal being impersonated.
    </description>
  </property>

  <property>
    <name>security.realm</name>
    <value>cdap</value>
    <description>
      Authentication realm used for scoping security; this value should be
      unique for each installation of CDAP
    </description>
  </property>

  <property>
    <name>security.server.extended.token.expiration.ms</name>
    <value>604800000</value>
    <description>
      Admin tool access token expiration time in milliseconds; defaults to 1
      week (internal)
    </description>
  </property>

  <property>
    <name>security.server.maxthreads</name>
    <value>100</value>
    <description>
      Maximum number of threads that the CDAP Authentication service should
      use for handling HTTP requests
    </description>
  </property>

  <property>
    <name>security.server.token.expiration.ms</name>
    <value>86400000</value>
    <description>
      Access token expiration time in milliseconds; defaults to 24 hours
    </description>
  </property>

  <property>
    <name>security.store.file.name</name>
    <value>securestore</value>
    <description>
      Name of the secure store file
    </description>
  </property>

  <property>
    <name>security.store.extensions.dir</name>
    <value>/opt/cdap/master/ext/securestores</value>
    <description>
      Semicolon-separated list of local directories that are scanned for secure store extensions
    </description>
  </property>

  <property>
    <name>security.store.file.path</name>
    <value>${local.data.dir}/store</value>
    <description>
      Location of the encrypted file which holds the secure store entries
    </description>
  </property>

  <property>
    <name>security.store.provider</name>
    <value>none</value>
    <description>
      Backend provider for the secure store; values can be 'none' if no secure store, 'kms' for hadoop kms based store
      or name of the secure store extension.
      If the provider is set to 'file' then the user must provide the password to be used to access the keystore.
      The password can be set using 'security.store.file.password' property in cdap-security.xml.
      KMS based provider is supported for Apache Hadoop 2.6.0 and above versions.
    </description>
  </property>

  <property>
    <name>security.token.digest.algorithm</name>
    <value>HmacSHA256</value>
    <description>
      Algorithm used for generating MAC of access tokens
    </description>
  </property>

  <property>
    <name>security.token.digest.key.expiration.ms</name>
    <value>3600000</value>
    <description>
      Duration in milliseconds after which an active secret key used for
      signing tokens should be retired
    </description>
  </property>

  <property>
    <name>security.token.digest.keylength</name>
    <value>128</value>
    <description>
      Key length used in generating the secret keys for generating MAC of
      access tokens
    </description>
  </property>

  <property>
    <name>security.token.distributed.parent.znode</name>
    <value>/${root.namespace}/security/auth</value>
    <description>
      Parent node in ZooKeeper used for secret key distribution in
      Distributed CDAP
    </description>
  </property>

  <property>
    <name>ssl.external.enabled</name>
    <value>false</value>
    <description>
      Enable SSL for external services
    </description>
  </property>

  <property>
    <name>ssl.internal.enabled</name>
    <value>false</value>
    <description>
      Enable SSL between internal services
    </description>
  </property>

  <property>
    <name>ssl.internal.cert.path</name>
    <value></value>
    <description>
      File path to certificate and private key file in PEM format to use when ssl.internal.enabled is set to true.
    </description>
  </property>

  <!-- Internal Security -->

  <property>
    <name>security.internal.auth.enabled</name>
    <value>false</value>
    <description>
      A security-hardening measure which enforces authenticated communication between internal system services.
    </description>
  </property>

  <property>
    <name>security.runtime.identity.compatibility.enabled</name>
    <value>true</value>
    <description>
      A backwards-compatibility setting which does not add the runtime identity handler to the runtime service. This
      setting is enabled by default for backwards compatibility but should not be used for new secure deployments.
    </description>
  </property>

  <!-- Authorization Metrics -->

  <property>
    <name>security.authorization.metrics.enabled</name>
    <value>false</value>
    <description>
      Whether to collect metrics for authorization checks.
    </description>
  </property>

  <property>
    <name>security.authorization.metrics.tags.enabled</name>
    <value>false</value>
    <description>
      Whether to enable entity tagging for authorization metrics for metrics aggregations.
    </description>
  </property>

  <!-- Authenticator Configuration -->
  <property>
    <name>remote.authenticator.extensions.dir</name>
    <value>/opt/cdap/master/ext/authenticators</value>
    <description>
      Semicolon-separated list of local directories that are scanned for CDAP remote authenticator extensions.
    </description>
  </property>

  <!-- UI Configuration -->

  <property>
    <name>dashboard.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      CDAP UI bind address
    </description>
  </property>

  <property>
    <name>dashboard.bind.port</name>
    <value>11011</value>
    <description>
      CDAP UI bind port
    </description>
  </property>

  <property>
    <name>dashboard.router.check.timeout.secs</name>
    <value>0</value>
    <description>
      Interval in seconds that the CDAP UI waits before exiting when unable
      to connect to the CDAP Router service on startup; use a timeout of 0
      to wait indefinitely
    </description>
  </property>

  <property>
    <name>dashboard.ssl.bind.port</name>
    <value>9443</value>
    <description>
      CDAP UI bind port for HTTPS
    </description>
  </property>

  <property>
    <name>dashboard.ssl.disable.cert.check</name>
    <value>false</value>
    <description>
      True to disable SSL certificate check from the CDAP UI
    </description>
  </property>

  <property>
    <name>http.client.connection.timeout.ms</name>
    <value>60000</value>
    <description>
      Connection timeout in milliseconds for internal HTTP requests
    </description>
  </property>

  <property>
    <name>http.client.read.timeout.ms</name>
    <value>60000</value>
    <description>
      Read timeout in milliseconds for internal HTTP requests
    </description>
  </property>

  <property>
    <name>program.heartbeat.interval.seconds</name>
    <value>1800</value>
    <description>
      Interval of heartbeat sent from program while it's running, default 30 minutes
    </description>
  </property>

  <property>
    <name>program.heartbeat.table.ttl.seconds</name>
    <value>2592000</value>
    <description>
      TTL duration for program heartbeat table, by default 30 days
    </description>
  </property>

  <property>
    <name>profile.update.allowed</name>
    <value>true</value>
    <description>
      Determine if new profile can be created or existing profile can be updated.
    </description>
  </property>

  <property>
    <name>system.program.scan.interval.seconds</name>
    <value>10</value>
    <description>
      Interval at which system programs are monitored in seconds
    </description>
  </property>
  <property>
    <name>capability.dir.scan.interval.minutes</name>
    <value>1</value>
    <description>
      Interval at which system programs are monitored in minutes
    </description>
  </property>
  <property>
    <name>capability.config.dir</name>
    <value>/opt/cdap/master/capability-config</value>
    <description>
      Internal directory that maintains the currently disabled and enabled configurations
    </description>
  </property>
  <property>
    <name>capability.autoinstall.threads</name>
    <value>5</value>
    <description>
      Number of threads to be used for auto installing resources when a capability is enabled
    </description>
  </property>

  <!-- event publisher -->
  <property>
    <name>event.program.status.poll.interval.seconds</name>
    <value>1</value>
    <description>
      Interval at which program status is polled for event publishing
    </description>
  </property>

  <property>
    <name>event.program.status.fetch.size</name>
    <value>100</value>
    <description>
      Number of program status messages fetched at a time
    </description>
  </property>

  <property>
    <name>feature.event.publish.enabled</name>
    <value>false</value>
    <final>false</final>
    <description>
      Enable event publish in CDAP
    </description>
  </property>

  <!-- Spark on k8s  -->
  <property>
    <name>artifact.fetcher.bind.port</name>
    <value>11013</value>
    <description>
      The bind port for artifact fetcher service
    </description>
  </property>

  <property>
    <name>driver.artifact.fetcher.worker.threads</name>
    <value>10</value>
    <description>
      The number of worker threads in the artifacts fetcher.
    </description>
  </property>

  <property>
    <name>driver.artifact.fetcher.exec.threads</name>
    <value>10</value>
    <description>
      The number of executor threads for the artifacts fetcher.
    </description>
  </property>

  <property>
    <name>driver.artifact.fetcher.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads for the artifacts fetcher.
    </description>
  </property>

  <!-- Task Worker Configuration  -->
  <property>
    <name>task.worker.pool.enable</name>
    <value>false</value>
    <description>
      If true, task worker pool will be created with twill application
    </description>
  </property>

  <property>
    <name>task.worker.compression.enabled</name>
    <value>true</value>
    <description>
      If true, enable compression for the network payloads with task workers.
    </description>
  </property>

  <property>
    <name>task.worker.pool.check.interval</name>
    <value>5</value>
    <description>
      Interval (in seconds) for ensuring task worker pool is up and running.
    </description>
  </property>

  <property>
    <name>task.worker.container.count</name>
    <value>2</value>
    <description>
      Number of task worker containers for task execution.
    </description>
  </property>

  <property>
    <name>task.worker.container.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for the task worker.
    </description>
  </property>

  <property>
    <name>task.worker.container.memory.mb</name>
    <value>400</value>
    <description>
      Memory in megabytes for each task worker.
    </description>
  </property>

  <property>
    <name>task.worker.container.disk.size.gb</name>
    <value>10</value>
    <description>
      Size of the stateful disk for the task worker.
    </description>
  </property>

  <property>
    <name>task.worker.container.disk.readonly</name>
    <value>true</value>
    <description>
      If true, disk volume will be mount as readonly.
    </description>
  </property>

  <property>
    <name>task.worker.container.kill.after.request.count</name>
    <value>100</value>
    <description>
      The number of executions by the task worker before it gets killed.
      Zero or negative values result in no pod restart.
    </description>
  </property>

  <property>
    <name>task.worker.container.kill.after.duration.second</name>
    <value>7200</value>
    <description>
      Duration (in seconds) to wait before killing the pod after it starts.
      Actual duration varies randomly within a defined range.
      Zero or negative values result in no periodic task worker restart.
    </description>
  </property>

  <property>
    <name>task.worker.preload.artifacts</name>
    <value></value>
    <description>
      A command separated list of system artifacts to be preloaded into each task worker
    </description>
  </property>

  <property>
    <name>task.worker.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      The bind address for task worker service.
    </description>
  </property>

  <property>
    <name>task.worker.bind.port</name>
    <value>11020</value>
    <description>
      The port to bind the task worker service to.
    </description>
  </property>

  <property>
    <name>task.worker.worker.threads</name>
    <value>10</value>
    <description>
      The number of worker threads in the task worker.
    </description>
  </property>

  <property>
    <name>task.worker.exec.threads</name>
    <value>10</value>
    <description>
      The number of executor threads for the task worker.
    </description>
  </property>

  <property>
    <name>task.worker.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads for the task worker.
    </description>
  </property>

  <property>
    <name>task.worker.container.jvm.opts</name>
    <value>-XX:+UseG1GC -XX:+ExitOnOutOfMemoryError</value>
    <description>
      JVM opts for task worker containers.
    </description>
  </property>

  <!-- System pods Configuration  -->
  <property>
    <name>system.worker.program.twill.controller.start.seconds</name>
    <value>${app.program.max.start.seconds}</value>
    <description>
      Sets value of app.program.twill.controller.start.seconds in system workers.
      This value should only be changed in hybrid setups.
      (TODO) CDAP-19405 to remove the need for this configuration
    </description>
  </property>

  <property>
    <name>system.worker.pool.enable</name>
    <value>false</value>
    <description>
      If true, task system pods will be created with twill application
    </description>
  </property>

  <property>
    <name>system.worker.container.count</name>
    <value>2</value>
    <description>
      Number of system worker containers for task execution.
    </description>
  </property>

  <property>
    <name>system.worker.container.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for the system worker.
    </description>
  </property>

  <property>
    <name>system.worker.container.memory.mb</name>
    <value>400</value>
    <description>
      Memory in megabytes for each system worker.
    </description>
  </property>

  <property>
    <name>system.worker.container.jvm.opts</name>
    <value>-XX:+UseG1GC -XX:+ExitOnOutOfMemoryError</value>
    <description>
      JVM opts for system worker containers.
    </description>
  </property>

  <property>
    <name>system.worker.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      The bind address for system worker service.
    </description>
  </property>

  <property>
    <name>system.worker.bind.port</name>
    <value>11020</value>
    <description>
      The port to bind the system worker service to.
    </description>
  </property>

  <property>
    <name>system.worker.request.limit</name>
    <value>10</value>
    <description>
      Number of requests accepted by system worker pods.
    </description>
  </property>

  <property>
    <name>system.worker.dispatch.program.types</name>
    <value>workflow</value>
    <description>
      comma separated list of ProgramTypes
    </description>
  </property>

  <property>
    <name>system.worker.http.client.read.timeout.ms</name>
    <value>300000</value>
    <description>
      Read timeout in milliseconds for system worker HTTP requests.
    </description>
  </property>

  <property>
    <name>system.worker.http.client.connection.timeout.ms</name>
    <value>60000</value>
    <description>
      Connection timeout in milliseconds for system worker HTTP requests.
    </description>
  </property>

  <property>
    <name>system.worker.artifact.localizer.enabled</name>
    <value>false</value>
    <description>
      If true, artifact localization will be enabled in system pods
    </description>
  </property>

  <property>
    <name>artifact.localizer.container.num.cores</name>
    <value>1</value>
    <description>
      Number of virtual cores for the task worker.
    </description>
  </property>

  <property>
    <name>artifact.localizer.container.memory.mb</name>
    <value>100</value>
    <description>
      Memory in megabytes for each task worker.
    </description>
  </property>

  <property>
    <name>artifact.localizer.bind.port</name>
    <value>11021</value>
    <description>
      The port to bind the artifact localizer service to.
    </description>
  </property>

  <property>
    <name>artifact.localizer.worker.threads</name>
    <value>10</value>
    <description>
      The number of artifact localizer threads in the file localizer sidecar container.
    </description>
  </property>

  <property>
    <name>artifact.localizer.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads for the artifact localizer.
    </description>
  </property>

  <property>
    <name>artifact.localizer.container.jvm.opts</name>
    <value>-XX:+UseG1GC -XX:+ExitOnOutOfMemoryError</value>
    <description>
      JVM opts for artifact localizer containers.
    </description>
  </property>

  <property>
    <name>file.localizer.container.jvm.opts</name>
    <value>-XX:+UseG1GC -XX:+ExitOnOutOfMemoryError</value>
    <description>
      JVM opts for file localizer containers.
    </description>
  </property>

  <property>
    <name>task.worker.local.data.dir</name>
    <value>/tmp</value>
    <description>
      The local data directory for the task worker container.
    </description>
  </property>

  <property>
    <name>artifact.localizer.cache.cleanup.interval.min</name>
    <value>60</value>
    <description>
      The interval (in minutes) that the cleanup service will delete old artifact cache files.
    </description>
  </property>

  <!-- Default values for Config-based request-blocking -->
  <property>
    <name>router.block.request.enabled</name>
    <value>false</value>
    <description>
      Determines whether server should start blocking inbound requests. If true, server would start
      responding to every request (not router health checks) with response declared in cconf.
    </description>
  </property>

  <property>
    <name>router.block.request.status.code</name>
    <value>503</value>
    <description>
      The status code if request-blocking is enabled.
    </description>
  </property>

  <property>
    <name>router.block.request.message</name>
    <value></value>
    <description>
      The response body if request-blocking is enabled.
    </description>
  </property>

  <!-- Service SupportBundle Configuration -->
  <property>
    <name>support.bundle.service.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      SupportBundle HTTP service bind address
    </description>
  </property>

  <property>
    <name>support.bundle.service.bind.port</name>
    <value>0</value>
    <description>
      SupportBundle HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <property>
    <name>support.bundle.service.exec.threads</name>
    <value>${http.service.exec.threads}</value>
    <description>
      Number of Netty service executor threads for supportBundle HTTP service
    </description>
  </property>

  <property>
    <name>support.bundle.service.worker.threads</name>
    <value>${http.service.worker.threads}</value>
    <description>
      Number of Netty service IO worker threads for supportBundle HTTP service
    </description>
  </property>

  <property>
    <name>support.bundle.service.memory.mb</name>
    <value>2048</value>
    <description>
      Memory in megabytes for support bundle service. This is
      explicitly set differently than ${master.service.memory.mb}.
    </description>
  </property>

  <property>
    <name>support.bundle.service.num.cores</name>
    <value>${master.service.num.cores}</value>
    <description>
      Number of virtual cores for the support bundle service
    </description>
  </property>

  <property>
    <name>support.bundle.container.instances</name>
    <value>1</value>
    <description>
      Number of instances for the support bundle service
    </description>
  </property>

  <property>
    <name>support.bundle.max.instances</name>
    <value>${master.service.max.instances}</value>
    <description>
      Maximum number of instances for the support bundle service.
    </description>
    <final>true</final>
  </property>

  <property>
    <name>support.bundle.local.data.dir</name>
    <value>${local.data.dir}/support/bundles</value>
    <description>
      Data directory for CDAP Support Bundle Local Sandbox
    </description>
  </property>

  <property>
    <name>support.bundle.max.folder.size</name>
    <value>7</value>
    <description>
      Number of folder allows for each bundle generated.
    </description>
  </property>

  <property>
    <name>support.bundle.max.retry.times</name>
    <value>3</value>
    <description>
      Number of retries allows for each bundle task processes.
    </description>
  </property>

  <property>
    <name>support.bundle.max.threads</name>
    <value>5</value>
    <description>
      Number of thread allows for support bundle generation.
    </description>
  </property>

  <property>
    <name>support.bundle.max.thread.timeout</name>
    <value>5</value>
    <description>
      Max 5 minutes allows for each thread process.
    </description>
  </property>

  <property>
    <name>support.bundle.system.log.start.time</name>
    <value>1</value>
    <description>
      system log start 1 day ago to collect logs
    </description>
  </property>

  <property>
    <name>support.bundle.temp.dir</name>
    <value>${local.data.dir}/support/tmp</value>
    <description>
      Support Bundle Temp directory for storing the support bundle zip file and use that generate download link
    </description>
  </property>

  <property>
    <name>tethering.agent.connection.interval.secs</name>
    <value>1</value>
    <description>
      Interval for connecting to the tethering server.
    </description>
  </property>

  <property>
    <name>tethering.agent.retry.policy.base.delay.ms</name>
    <value>10000</value>
    <description>
      The base delay between retries in milliseconds
    </description>
  </property>

  <property>
    <name>tethering.agent.retry.policy.max.retries</name>
    <value>8640</value>
    <description>
      The maximum number of retries to attempt before aborting
    </description>
  </property>

  <property>
    <name>tethering.agent.retry.policy.max.time.secs</name>
    <value>86400</value>
    <description>
      The maximum elapsed time in seconds before retries are aborted
    </description>
  </property>

  <property>
    <name>tethering.agent.retry.policy.type</name>
    <value>fixed.delay</value>
    <description>
      The type of retry policy for metrics publishing. Allowed options:
      "none", "fixed.delay", or "exponential.backoff".
    </description>
  </property>

  <property>
    <name>tethering.topic.prefix</name>
    <value>tethering_</value>
    <description>
      TMS topic prefix used on tethering server
    </description>
  </property>

  <property>
    <name>tethering.client.connection.timeout.ms</name>
    <value>${http.client.connection.timeout.ms}</value>
    <description>
      Tethering client connection timeout in milliseconds.
    </description>
  </property>

  <property>
    <name>tethering.client.read.timeout.ms</name>
    <value>${http.client.read.timeout.ms}</value>
    <description>
      Tethering client read timeout in milliseconds.
    </description>
  </property>

  <property>
    <name>tethering.server.enabled</name>
    <value>false</value>
    <description>
      Determines if tethering server should be enabled.
    </description>
  </property>

  <property>
    <name>tethering.program.dir</name>
    <value>program-resources</value>
    <description>
      Directory that contains resources needed for tethered program runs.
    </description>
  </property>

  <property>
    <name>tethering.control.message.batch.size</name>
    <value>100</value>
    <description>
      Maximum number of control messages sent by tethering server in response to poll.
    </description>
  </property>

  <property>
    <name>jmx.metrics.collector.poll.interval.secs</name>
    <value>60</value>
    <description>
      Interval (in seconds) for polling JMXServer for resource utilization metrics.
    </description>
  </property>

  <property>
    <name>jmx.server.port</name>
    <value>11022</value>
    <description>
      Port to be exposed on localhost to allow metrics collection using JMX.
    </description>
  </property>

  <property>
    <name>preview.max.num.records</name>
    <value>5000</value>
    <description>
      The maximum number of records that can be set in preview configuration.
    </description>
  </property>

  <property>
    <name>feature.replication.transformations.enabled</name>
    <value>true</value>
    <description>
      Enables transformations to be run on replication.
    </description>
  </property>

  <property>
    <name>feature.pipeline.composite.triggers.enabled</name>
    <value>true</value>
    <description>
      Enables configuring composite AND/OR triggers for a pipeline schedule.
    </description>
  </property>

  <property>
    <name>feature.lifecycle.management.edit.enabled</name>
    <value>true</value>
    <description>
      Enables Design-time Lifecycle Management for applications.
    </description>
  </property>

  <property>
    <name>feature.pushdown.transformation.groupby.enabled</name>
    <value>true</value>
    <description>
      Enables group by transformation in pushdown execution.
    </description>
  </property>

  <property>
    <name>feature.pushdown.transformation.deduplicate.enabled</name>
    <value>true</value>
    <description>
      Enables deduplicate transformation in pushdown execution.
    </description>
  </property>

  <property>
    <name>feature.pushdown.transformation.windowaggregation.enabled</name>
    <value>true</value>
    <description>
      Enables Window aggregation transformation in pushdown execution.
    </description>
  </property>

  <property>
    <name>feature.streaming.pipeline.checkpoint.deletion.enabled</name>
    <value>false</value>
    <description>
      Enables auto deletion of streaming pipeline checkpoint on successful graceful shutdown
    </description>
  </property>

  <property>
    <name>feature.streaming.pipeline.native.state.tracking.enabled</name>
    <value>true</value>
    <description>
      Enable native state tracking for streaming pipelines for Atleast Once guarantee
    </description>
  </property>

  <property>
    <name>feature.wrangler.fail.pipeline.for.error.enabled</name>
    <value>false</value>
    <description>
      Enables pipeline failures when Wrangler transformations fail in 'Fail Pipeline' mode
    </description>
  </property>

  <property>
    <name>artifact.cache.bind.address</name>
    <value>0.0.0.0</value>
    <description>
      The bind address for artifact service.
    </description>
  </property>

  <property>
    <name>artifact.cache.bind.port</name>
    <value>0</value>
    <description>
      The port to bind the artifact cache service to.
    </description>
  </property>

  <property>
    <name>artifact.cache.worker.threads</name>
    <value>10</value>
    <description>
      The number of worker threads in the artifact cache service.
    </description>
  </property>

  <property>
    <name>artifact.cache.boss.threads</name>
    <value>1</value>
    <description>
      The number of boss threads in the artifact cache service.
    </description>
  </property>

  <property>
    <name>artifact.cache.local.data.dir</name>
    <value>${local.data.dir}/artifact.cache</value>
    <description>
      The local data directory for the artifact cache container.
    </description>
  </property>

  <property>
    <name>artifact.cache.cache.cleanup.interval.min</name>
    <value>60</value>
    <description>
      The interval (in minutes) that the cleanup service will delete old artifact cache files.
    </description>
  </property>

  <!-- Service Health Check Service Port Configuration -->
  <property>
    <name>healthcheck.service.bind.port</name>
    <value>0</value>
    <description>
      Health Check HTTP service bind port; if 0, binds to a random port
    </description>
  </property>

  <!-- Configuration for Source Control Management -->
  <property>
    <name>feature.source.control.management.git.enabled</name>
    <value>false</value>
    <final>true</final>
    <description>
      If true, source control management using git will be enabled.
    </description>
  </property>

</configuration>
