[
  {
    "status": "COMPLETE",
    "stageId": 0,
    "attemptId": 0,
    "numTasks": 1,
    "numActiveTasks": 0,
    "numCompleteTasks": 1,
    "numFailedTasks": 0,
    "numKilledTasks": 0,
    "numCompletedIndices": 1,
    "executorRunTime": 10405,
    "executorCpuTime": 7246078873,
    "submissionTime": "2022-02-07T23:20:22.080GMT",
    "firstTaskLaunchedTime": "2022-02-07T23:20:36.409GMT",
    "completionTime": "2022-02-07T23:20:48.710GMT",
    "inputBytes": 6046096,
    "inputRecords": 10195,
    "outputBytes": 6237,
    "outputRecords": 22,
    "shuffleReadBytes": 0,
    "shuffleReadRecords": 0,
    "shuffleWriteBytes": 0,
    "shuffleWriteRecords": 0,
    "memoryBytesSpilled": 0,
    "diskBytesSpilled": 0,
    "name": "runJob at SparkHadoopWriter.scala:83",
    "details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2257)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1077)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1075)\norg.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopDataset(JavaPairRDD.scala:833)\nio.cdap.cdap.etl.spark.batch.RDDUtils.saveHadoopDataset(RDDUtils.java:58)\nio.cdap.cdap.etl.spark.batch.RDDUtils.saveUsingOutputFormat(RDDUtils.java:47)\nio.cdap.cdap.etl.spark.batch.SparkBatchSinkFactory.writeFromRDD(SparkBatchSinkFactory.java:175)\nio.cdap.cdap.etl.spark.batch.BaseRDDCollection$1.run(BaseRDDCollection.java:239)\nio.cdap.cdap.etl.spark.SparkPipelineRunner.runPipeline(SparkPipelineRunner.java:383)\nio.cdap.cdap.etl.spark.batch.BatchSparkPipelineDriver.run(BatchSparkPipelineDriver.java:218)\nio.cdap.cdap.app.runtime.spark.SparkTransactional$2.run(SparkTransactional.java:236)\nio.cdap.cdap.app.runtime.spark.SparkTransactional.execute(SparkTransactional.java:208)\nio.cdap.cdap.app.runtime.spark.SparkTransactional.execute(SparkTransactional.java:138)\nio.cdap.cdap.app.runtime.spark.AbstractSparkExecutionContext.execute(AbstractSparkExecutionContext.scala:227)\nio.cdap.cdap.app.runtime.spark.SerializableSparkExecutionContext.execute(SerializableSparkExecutionContext.scala:61)",
    "schedulingPool": "default",
    "rddIds": [
      5,
      4,
      2,
      0,
      3,
      1
    ],
    "accumulatorUpdates": [],
    "killedTasksSummary": {}
  }
]